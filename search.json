[
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "beter: Beast Templates in R, another way how to create input XML files for the Beast phylogenetic software.\nbaffle: make a waffle plots in base R graphics!\nrrnni: compute phylogenetic distances in the RNNI space"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Moravec, J. C., Lanfear, R., Spector, D. L., Diermeier, S. D., & Gavryushkin, A. (In Press). Testing for phylogenetic signal in single-cell RNA-seq data. Journal of Computational Biology. https://doi.org/10.1101/2021.01.07.425804\n\n\nChen, K., Moravec, J. C., Gavryushkin, A., Welch, D., & Drummond, A. J. (2022). Accounting for Errors in Data Improves Divergence Time Estimates in Single-cell Cancer Evolution. Molecular Biology and Evolution, 39(8), msac143. https://doi.org/10.1093/molbev/msac143\n\n\nPowell, R. M., Pattison, S., Moravec, J. C., Bhat, B., Guirguis, N., Markie, D., Jones, G. T., Copedo, J., Print, C. G., Morison, I. M., Gavryushkin, A., Gray, B., Wyeth, L. J., Eccles, M. R., & Macaulay, E. C. (2022). Tuberous sclerosis complex: A complex case. Cold Spring Harbor Molecular Case Studies, 8(3), a006182. https://doi.org/10.1101/mcs.a006182\n\n\nMoravec, J. C., Marsland, S., & Cox, M. P. (2019). Warfare induces post-marital residence change. Journal of Theoretical Biology, 474, 52–62.\n\n\nHarazim, M., Horáček, I., Jakešová, L., Luermann, K., Moravec, J. C., Morgan, S., Pikula, J., Sosík, P., Vavrušová, Z., Zahradníková, A., Zukal, J., & Martínková, N. (2018). Natural selection in bats with historical exposure to white-nose syndrome. BMC Zoology, 3(1), 8.\n\n\nMoravec, J. C., Atkinson, Q., Bowern, C., Greenhill, S. J., Jordan, F. M., Ross, R. M., Gray, R., Marsland, S., & Cox, M. P. (2018). Post-marital residence patterns show lineage-specific evolution. Evolution and Human Behavior, 39(6), 594–601.\n\n\nPečnerová, P., Moravec, J. C., & Martínková, N. (2015). A skull might lie: Modeling ancestral ranges and diet from genes and shape of tree squirrels. Systematic Biology, 64(6), 1074–1088.\n\n\nJaron, K. S., Moravec, J. C., & Martínková, N. (2014). SigHunt: Horizontal gene transfer finder optimized for eukaryotic genomes. Bioinformatics, 30(8), 1081–1086.\n\n\nMartínková, N., & Moravec, J. (2012). Multilocus phylogeny of arvicoline voles (Arvicolini, Rodentia) shows small tree terrace size. Folia Zoologica, 61(3–4), 254–267."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jiří C. Moravec",
    "section": "",
    "text": "Learn SQL with me: NZ names\n\n\n\n\n\n\n\nsql\n\n\nNZ names\n\n\n\n\nSQL, database design and the most popular names in New Zealand\n\n\n\n\n\n\nMar 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDigital Cubism (1)\n\n\n\n\n\n\n\nR\n\n\ngraphics\n\n\n\n\nKmeans and CART\n\n\n\n\n\n\nMar 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase R from A to Z: Operators (3)\n\n\n\n\n\n\n\nR\n\n\n\n\nArithmetic, Logical and Relational operators\n\n\n\n\n\n\nMar 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase R from A to Z: Types of functions (2)\n\n\n\n\n\n\n\nR\n\n\n\n\nClosures, primitives and internals\n\n\n\n\n\n\nFeb 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase R from A to Z: Introduction (1)\n\n\n\n\n\n\n\nR\n\n\n\n\nOverview of preinstalled packages\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHello World!\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jiří C. Moravec",
    "section": "",
    "text": "I am a computational biologist, bioinformatician, statistician, or just data scientist for short.\nMy main interests are phylogenetic trees and their applications, while traditionally phylogenetic trees are used to estimate the evolutionary relationship of biological species from DNA, I have applied phylogenetic trees to study population dynamics of viruses, animals, cancer cells and languages.\nMy language of choice is typically R as it is usually the fastest way to read and process data. But I am proficient with Python, C/C++ and Java as well.\nHere you can view my publications or CV."
  },
  {
    "objectID": "posts/digital_cubism/1_kmeans_cart.html",
    "href": "posts/digital_cubism/1_kmeans_cart.html",
    "title": "Digital Cubism (1)",
    "section": "",
    "text": "knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)\n\nI generaly do not like cubism, to me it looks messy, with body parts all over the place. But there is a subset of cubism that appeals to me, pieces like Girl with Mandolin, with the sharp outline and geometric appearance, yet the figure is still easily recognized.\n\n\n\nGirl with mandolin, Credit: Wikipedia\n\n\nThis gave me an idea to try approximate image with a series of geometric shapes. Ideally, we would use only a few squares, rectangles and so on, but achieve a recognizable image. Mabye this is isn’t truly cubism, but more something akin to mosaic or Stained Glass technique but it sounds like fun.\nI wasn’t the only one who came with this idea. Found an R blog is.R(), who approached this problem through k-means.\nFor these experiments, I will use my own photo, there are plenty convenient colour contrasts, but you can use whatever you want.\n\nk-means\nFirst, we will reproduce the technique through k-means. This is quite smart idea, because the code is really simple. We just need to unroll an image from its raster representation (RGB array) into a data.frame, and back.\n\n\nCode\nimage2df = function(img){\n    cols = ncol(img)\n    rows = nrow(img)\n\n    x = rep(seq_len(cols), each=rows)\n    y = rep(seq_len(rows), times=cols)\n\n    # R matrices are in column format, so we can just convert them to vectors\n    r = img[,,1] |> as.vector()\n    g = img[,,2] |> as.vector()\n    b = img[,,3] |> as.vector()\n\n    data.frame(x = x, y = y, r = r, g = g, b = b)\n    }\n\n\ndf2image = function(df){\n    img = array( dim = c(max(df$y), max(df$x), 3) )\n    img[,,1] = df$r\n    img[,,2] = df$g\n    img[,,3] = df$b\n\n    structure(img, class = c(\"image\", \"array\"))\n    }\n\n\nplot.image = function(x){\n    plot.new()\n    par(\"mar\" = c(0, 0, 0, 0))\n    plot.window(c(1, ncol(x)), c(1, nrow(x)), xaxs = \"i\", yaxs = \"i\", asp=1)\n    rasterImage(x, 1, 1, ncol(x), nrow(x), interpolate = FALSE)\n    }\n\n\nOnce we have that, applying k-means is simple:\n\nkmeans.image = function(img, centers, iter.max = 10, ...){\n    df = image2df(img)\n    means = kmeans(df, centers, iter.max = iter.max, ...)\n    color = means$centers[means$cluster, 3:5]\n    df2 = cbind(df[,1:2], color)\n    img2 = df2image(df2)\n    img2\n    }\n\n\nlibrary(\"jpeg\")\n\n# use your own image here\nimg = structure( readJPEG(\"profile.jpg\"), class = c(\"image\", \"array\") )\nkmeans.image(img, 500) |> plot.image()\n\n\n\n\nAll we do here is basically applying k-means on the coordinates. This means that all we are doing is constructing voronoi polygons. The colour information does not seem to have a strong effect because on the 0-1 scale, the colour differences are miniscule compared to differences between coordinates. Yet, running kmeans with colour calculates the average colour of each polygon.\nThe number of polygons used to approximate the image has quite an visual effect, from a more abstract cubic-like drawing, to a mosaic-like appearance.\n\npar(\"mfrow\" = c(2,3))\nfor(i in c(50, 100, 200, 500, 1000, 2000))\n    kmeans.image(img, i) |> plot.image()\n\n\n\n\nThe difference might be quite apparent for a terrain pictures, such as this one from New Zealand:\n\npar(\"mfrow\" = c(1,1))\nterrain = structure( readJPEG(\"terrain.jpg\"), class = c(\"image\", \"array\") )\nterrain |> plot.image()\n\n\n\npar(\"mfrow\" = c(2,3))\nfor(i in c(50, 100, 200, 500, 1000, 2000))\n    kmeans.image(terrain, i) |> plot.image()\n\n\n\n\nOn the higher range (200 and more), it lookst just as pixelation. Small number of polygons are not able to approximate the look of the image well enough, but 200-1000 looks like a sweet spot.\n\n\nCART\nOriginally I planned to go with this polygonal approach and do some adaptive voronoi polygons, move the points so that the error of the approximation is minimal. But then I was thinking, are there some other classical statistical methods that would be easily adaptable to this problem?\nThink what we want to do, divide image into areas. Well, the CART does just that, it divides the dimensions of the explanatory variables into subsets, and the response in each subset is the average response of all points in the subset. This is quite close to what we want to do! And since we have our image in a data.frame representation, running the CART algorithm is easy!\n\nlibrary(\"tree\")\ntree.image = function(img, ...){\n    df = image2df(img)\n    \n    col = list()\n    for(i in c(\"r\",\"g\",\"b\")){\n        fit = paste0(i, \" ~ x + y\") |> formula() |> tree(data=df, ...)\n        col[[i]] =  predict(fit, df)\n        }\n\n    df[names(col)] = col\n    img2 = df2image(df)\n    img2\n    }\n\ntree.image(img) |> plot.image()\n\n\n\n\nThe disadvantage of this approach is that the tree() does not allows for a multiple dependent variables, so we need to run the algorithms in each colour space separately.\n\n\nCode\n# Modified version of plot.image\n# plot a selection of the colour layers\nplot.image = function(x, col=c(\"r\",\"g\",\"b\")){\n    col = match.arg(col, several = TRUE)\n    for( i in which(!c(\"r\",\"g\",\"b\") %in% col))\n        x[,,i] = 0\n\n    plot.new()\n    par(\"mar\" = c(0,0,0,0))\n    plot.window(c(1, ncol(x)), c(1, nrow(x)), xaxs = \"i\", yaxs = \"i\", asp=1)\n    rasterImage(x, 1, 1, ncol(x), nrow(x), interpolate=FALSE)\n    }\n\npredicted = tree.image(img)\n\npar(\"mfrow\"=c(1,3))\nfor(i in c(\"r\",\"g\",\"b\"))\n    plot.image(predicted, i)\n\n\n\n\n\nSurprisingly, the information carried by green and blue is almost identical. Only reds seems to carry significantly different information.\nWhat controls the amount of approximation is the mindev parameter, other parameters starts to have an effect as a stopping parameters only when mindev is decreased significantly.\n\n\nCode\npar(\"mfrow\"=c(1,1))\ntree.image(img, mindev=10^-4) |> plot.image()\n\n\n\n\n\nCode\npar(\"mfrow\" = c(1,3))\nfor(i in c(10^-3, 10^-4, 10^-5))\n    tree.image(img, mindev=i) |> plot.image()\n\n\n\n\n\nLooks like CART can produce a sharper borders, the outline of is already quite visible with mindev=10^-3. But it doesn’t handle details well, unless we use a CART tree with a lot of tips.\nSo like before, lets look how this method works on terrain:\n\n\nCode\npar(\"mfrow\"=c(1,1))\ntree.image(terrain, mindev=10^-4) |> plot.image()\n\n\n\n\n\nCode\npar(\"mfrow\" = c(1, 3))\nfor(i in c(10^-3, 10^-4, 10^-5))\n    tree.image(terrain, mindev=i) |> plot.image()\n\n\n\n\n\n\n\nSummary\nYou can do some cool things with R in just a few lines if you apply basic machine-learning methods creatively. The results are not exactly what I wanted however, so I will try to look into this problem a bit more, such as implementing the CART algorithm for multiple response variables."
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html",
    "href": "posts/sql_nz_names/sql_nz_names.html",
    "title": "Learn SQL with me: NZ names",
    "section": "",
    "text": "In this blogpost, we will look at the most popular names in New Zealand and build a relational database out of them. We will go through database design, such as first, second and third normal form, consider how the database will be used, how the data will be queried, and how to try to de-duplicate any information.\nNote of warning: I am not an expert on database design or SQL, I am just learning and trying to put the theoretical knowledge of a few books into practice using an interesting project that is more than just a toy example."
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-data",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-data",
    "title": "Learn SQL with me: NZ names",
    "section": "The Data",
    "text": "The Data\nThe data we will be working with comes from the Department of Internal Affairs. It contains the 100 most popular male and female names from 1954 to 2022. The data is presented as a series of columns containing a tuple (name, count), with male and female names separated into their own tables.\n\n\n\n\n\n\n\n\n\n\n\n\nRank\n1954\n-\n1955\n-\n1956\n-\n\n\n\n\n-\nName\nCount\nName\nCount\nName\nCount\n\n\n1\nChristine\n779\nSusan\n743\nSusan\n851\n\n\n2\nSusan\n735\nChristine\n689\nChristine\n754\n\n\n3\nMargaret\n562\nMargaret\n559\nKaren\n615\n\n\n\nFor the following database design, there are some considerations:\n\nEach column contains 100 names, but that doesn’t mean that we are operating with only 100 names. Some names popular in 1960 might not be popular in 2000.\nThe data covers names over 69 years, but we would like to make adding new data (new years) easy.\nSome names are unisex and may appear in both girl and boy tables. For instance, Ashley used to be a popular unisex name in the 1980s.\n\nThe data is presented in what would one call the wide format. We could go even wider by including a sex column and merging the tables into a single wide table, moving each name into its row and removing rank, and so on.\nConsider a much simpler row-oriented long format:\n\n\n\nName\nYear\nCount\n\n\n\n\nChristine\n1954\n779\n\n\nSusan\n1954\n735\n\n\nMargaret\n1954\n562\n\n\nSusan\n1955\n743\n\n\nChristine\n1955\n689\n\n\nMargaret\n1955\n559\n\n\n\nWe could easily add an additional column for sex and represent the whole data with just 4 columns. Or 5, if we also include rank, but rank feels like a derived variable. We can imagine that new data, such as a newly discovered book from a now-defunct hospital could bring information about a few more births such that historical rank would change. We would have to recalculate the rank.\nIn data science, the long format is especially popular because it is easy to work with. And from my experience, it is much easier for software to grog a million rows rather than a million columns.\nBoth of these forms are flat file representations, something you would get in a CSV file (and loaded in an R or such)."
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-design",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-design",
    "title": "Learn SQL with me: NZ names",
    "section": "The Design",
    "text": "The Design\nWhen designing the SQL table, we want to consider a few issues:\n\nhow the data will be queried\ndesign a database to prevent duplication\ndesign a database to prevent adding invalid data\n\nInvalid data and duplication is prevented by normalizing the database schema, the famous first, second and third normal forms. Database in Depth from C. J. Date mentions fourth and fifth normal forms and more, but that book feels to me very theoretical, it will probably make more sense to me once I am a bit more familiar with the practice.\nOn the other hand, the practical usage of the database might sometimes run against normalization. Apparently, there is a lot of discussion about the need for normalization or, on the other hand, considering normalization as common sense.\nFirst of all, the wide format. If we had only a few columns, it would be incredibly easy to define a names table, to serve as a foreign key, and then a table for every year, such as year1954, year1955 and so on. Querying data and joining tables would be relatively easy. And since there is no relationship between years, they all would depend only on the names table, adding an additional year table would be relatively easy.\n\n\n\nExample of a database design using the wide format.\n\n\nHowever, most databases are optimized towards rows, not columns. Adding a new table is a relatively expensive operation compared to adding an additional row. This way, we would end with 69 tables for each year, with more tables every year. That is quite a lot of tables! Additionally, if we would like to know the most common name since 1954, we would have to query every single table.\nYet, this approach has some advantages. Typically, old tables are not modified and tables are populated only once. New tables are added only once a year as the data are obtained. The database structure would be simple, every name could occur in every year table only once, giving it a simple constraint.\nWhat I think would be a better and more traditional approach is to model this relationship as one-to-many, one name to many years. We would have a name table, years table, and a value table. The first two tables are simple tables containing names or years respectively.\n\n\n\nExample of a database design using the long format.\n\n\nAnd this is the database we will implement."
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-implementation",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-implementation",
    "title": "Learn SQL with me: NZ names",
    "section": "The Implementation",
    "text": "The Implementation\nThe primary key is a constraint that uniquely identifies every row of a table. Each table can have only a single primary key. This is an incredibly powerful tool to enforce the integrity of a table.\nSimilarly, the foreign key is a field that refers to a primary key of another table, this enforces referential integrity.\nA common practice is to create an ID that serves as a primary key, but we do not need that. We might need it if we allowed for varied spelling and treated all instances of that as a single unique name.\nCREATE TABLE Names (\n    name varchar(50),\n    PRIMARY KEY (name)\n);\n\nCREATE TABLE Years (\n    year int,\n    PRIMARY KEY (year)\n);\nThe _counts_ table is more interesting. We know that we can have any combination of a name and a year, but each combination can be in a table only once. We can enforce this by creating a primary key from a tuple of (name, year) while enforcing that both of these values depend on the Names and Years table through foreign keys.\nCREATE TABLE Counts (\n    name varchar(50) NOT NULL,\n    year int NOT NULL,\n    count int NOT NULL,\n    PRIMARY KEY (name, year),\n    FOREIGN KEY (name) REFERENCES Names(name),\n    FOREIGN KEY (year) REFERENCES Years(year)\n);\nNow we can populate tables:\nINSERT INTO Years(year) VALUES (1954);\n\nINSERT INTO Names(name) VALUES (\"Christine\");\nINSERT INTO Counts (name, year, count) VALUES (\"Christine\", 1954, 779);\n\nINSERT INTO Names(name) VALUES (\"Susan\");\nINSERT INTO Counts (name, year, count) VALUES (\"Susan\", 1954, 735);\n\nINSERT INTO Names(name) VALUES(\"Margaret\");\nINSERT INTO Counts (name, year, count) VALUES (\"Margaret\", 1954, 562);\nThe Names table is a bit extra but gives us referential integrity. It protects us against typos, gives us the option to include a potential Rank table, and would allow us to add alternative spelling, translation and other features. It gives us also a visible list of all names. All these advantages are, I think, worth a little more pain when populating tables.\nNow, populating tables manually is a pain, so here we do it in R using the DBI and RSQLite packages.\n\n\nClick to unroll\n\nFirst, we need to parse the file and get data for boys and girls:\nlibrary(\"openxlsx\")\nfile = \"Top-100-girls-and-boys-names-since-1954.xlsx\"\n\n\nget_name_table = function(file, sheet){\n    # The raw data has rather complex structure:\n    #  * 4 rows are noise/empty\n    #  * 2 rows of headers (year and name/number)\n    #  * 1 empty row\n    #  * 100 rows of data\n    #   * 3 rows are noise/empty\n    # Helper function\n    get_year_table = function(data, cols, year){\n        data.frame(\"Name\" = data[,cols[1]],\n                   \"Year\" = as.integer(year),\n                   \"Count\" = data[,cols[2]])\n        }\n\n    data = openxlsx::read.xlsx(\n        file, sheet=sheet,\n        skipEmptyCols=FALSE, skipEmptyRows=FALSE,\n        colNames=FALSE\n        )\n\n    # Automatic skipEmptyCols and skipEmptyRows does not work properly in this case\n    data = data[-(1:4),] # 4 rows are noise\n    data = head(data, n=-3) # last 3 rows of noise\n    data = data[,-(1:2)] # First two columns are noise/rank\n\n    # convert to numeric first to remove any NAs that would turn into \"NA\" string otherwise\n    years = as.numeric(data[1,]) |> na.omit() |> c() |> as.character()\n\n    # Now we can remove the 2 rows of header and one empty row\n    data = data[-(1:3),]\n\n    # First year is formed by two column (name, value)\n    res = list()\n    res[[years[1]]] = get_year_table(data, c(1,2), years[1])\n\n    # Every other year is formed by three column (empty, name, value)\n    for(i in seq(2, length(years))){\n        cols = 2:3+3*(i-2)+2\n        year = years[i]\n        res[[year]] = get_year_table(data, cols, year)\n        }\n\n    res = do.call(rbind, res)\n    rownames(res) = NULL\n\n    res\n    }\n\ngirls = get_name_table(file, 1)\nboys = get_name_table(file, 2)\nThen we create tables as shown before:\nlibrary(\"RSQLite\")\nlibrary(\"DBI\")\nlibrary(\"glue\") # for better multiline strings\ndatabase = dbConnect(RSQLite::SQLite(), \"nznames.db\")\n\n# Names and counts splitted according to gender\ndbExecute(database, \"PRAGMA foreign_keys = ON;\") |> invisible()\ndbExecute(database, glue(\"\n    CREATE TABLE GirlNames (\n        name varchar(50),\n        PRIMARY KEY (name)\n    );\")) |> invisible()\n\ndbExecute(database, glue(\"\n    CREATE TABLE BoyNames (\n        name varchar(50),\n        PRIMARY KEY (name)\n    );\")) |> invisible()\n\ndbExecute(database, glue(\"\n    CREATE TABLE Years (\n        year int,\n        PRIMARY KEY (year)\n    );\")) |> invisible()\n\ndbExecute(database, glue(\"\n    CREATE TABLE GirlCounts (\n        name varchar(50) NOT NULL,\n        year int NOT NULL,\n        count int NOT NULL,\n        PRIMARY KEY (name, year),\n        FOREIGN KEY (name) REFERENCES GirlNames(name),\n        FOREIGN KEY (year) REFERENCES Years(year)\n    );\")) |> invisible()\n\ndbExecute(database, glue(\"\n    CREATE TABLE BoyCounts (\n        name varchar(50) NOT NULL,\n        year int NOT NULL,\n        count int NOT NULL,\n        PRIMARY KEY (name, year),\n        FOREIGN KEY (name) REFERENCES BoyNames(name),\n        FOREIGN KEY (year) REFERENCES Years(year)\n    );\")) |> invisible()\nAnd now we can populate tables:\nyears = data.frame(\"year\"=union(girls$Year, boys$Year) |> sort())\ngirl_names = data.frame(\"name\" = girls$Name |> unique())\nboy_names = data.frame(\"name\" = boys$Name |> unique())\n\ndbAppendTable(database, \"Years\", years)\ndbAppendTable(database, \"GirlNames\", girl_names)\ndbAppendTable(database, \"BoyNames\", boy_names)\ndbAppendTable(database, \"GirlCounts\", girls)\ndbAppendTable(database, \"BoyCounts\", boys)\nInterestingly, the last statement fails because a primary key would be duplicated. How so? Turns out someone typed Michael twice!\nany(duplicated(boys[,1:2]))\n\nfind_duplicated = function(x, cols){\n    x[duplicated(x[,cols]) | duplicated(x[,cols], fromLast=TRUE),]\n    }\nfind_duplicated(boys, 1:2)\nIn 1989, 741 boys were named Michael. And somehow also 52 boys. This is surely wrong and given the popularity of Michael, the second occurence is surely wrong. Unfortunately, we don’t know what the true value should be. Maybe if they used properly designed database like we did, it would warn them about this typo!\nSo we clean the data and rerun the statement.\nboys = boys[-anyDuplicated(boys[,1:2]),]\ndbAppendTable(database, \"BoyCounts\", boys)\ndbDisconnect(database)\n\nNow that we have the database, we can construct queries!"
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-querying",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-querying",
    "title": "Learn SQL with me: NZ names",
    "section": "The Querying",
    "text": "The Querying\nSelect the most popular girl name since 2010:\nSELECT name, MAX(count),year\nFROM GirlCounts\nWHERE year >= 2010\nGROUP BY year;\n\n\nClick to unroll\n\nRuby|335|2011\nOlivia|312|2012\nCharlotte|303|2013\nCharlotte|255|2014\nOlivia|268|2015\nOlivia|266|2016\nCharlotte|277|2017\nCharlotte|233|2018\nAmelia|255|2019\nIsla|243|2020\nCharlotte|227|2021\nIsla|246|2022\n\nCharlotte seems to be quite popular, how popular was the name historically?\nSELECT count, year\nFROM GirlCounts\nWHERE name == \"Charlotte\";\n\n\nClick to unroll\n\n65|1974\n65|1975\n75|1976\n106|1977\n93|1978\n95|1979\n88|1980\n85|1981\n93|1982\n111|1983\n87|1984\n106|1985\n135|1986\n123|1987\n118|1988\n158|1989\n149|1990\n155|1991\n175|1992\n155|1993\n160|1994\n130|1995\n140|1996\n138|1997\n133|1998\n150|1999\n149|2000\n152|2001\n201|2002\n243|2003\n330|2004\n278|2005\n324|2006\n263|2007\n269|2008\n257|2009\n305|2010\n258|2011\n285|2012\n303|2013\n255|2014\n260|2015\n262|2016\n277|2017\n233|2018\n248|2019\n222|2020\n227|2021\n208|2022\n\nCharlotte started to be popular since 1974 and steadily increase till 2010, after which it begun to drop slightly.\nAnother interesting question would be to find names that are steadily popular over the 69 year period. This means names that occur multiple times in our table.\nSELECT name, count(name)\nFROM GirlCounts\nGROUP BY name\nORDER BY COUNT(name) DESC;\n\n\nClick to unroll\n\nElizabeth|69\nAnna|63\nSarah|62\nMaria|56\nEmma|54\nVictoria|50\nCharlotte|49\nJennifer|49\nEmily|48\nStephanie|47\nOlivia|46\nRebecca|46\nCatherine|45\nHannah|45\nAlice|44\nAmber|44\nMegan|44\nHayley|43\nJessica|43\nMichelle|43\nJasmine|42\nKate|42\nLucy|42\nNatalie|42\nRachel|42\nKatherine|41\nKathryn|41\nLouise|41\nAngela|40\nNicola|40\nNicole|39\nSophie|39\nAmy|38\nAmanda|37\nAmelia|37\nChristina|37\nChristine|37\nHelen|37\nHolly|37\nKatie|37\nMary|37\nSamantha|37\nGrace|36\nLeah|36\nLisa|36\nMelissa|36\nChloe|35\nJade|35\nNatasha|35\nZoe|35\nClaire|34\nJane|34\nLauren|34\nGeorgia|33\nJacqueline|33\nJoanne|33\nJulie|33\nKaren|33\nAndrea|32\nFiona|32\nTracey|32\nAbigail|31\nDeborah|31\nDonna|31\nRuby|31\nToni|31\nLaura|30\nPaige|30\nSusan|30\nAlexandra|29\nBrooke|29\nCaroline|29\nDanielle|29\nElla|29\nJulia|29\nKayla|29\nKelly|29\nMadison|29\nMelanie|29\nRenee|29\nTania|29\nVanessa|29\nAimee|28\nEden|28\nIsabella|28\nKim|28\nSharon|28\nTeresa|28\nWendy|28\nHeather|27\nMaddison|27\nPaula|27\nPhoebe|27\nRose|27\nSophia|27\nSuzanne|27\nAlison|26\nAshley|26\nKatrina|26\nLily|26\nMarie|26\nRachael|26\nSally|26\nShannon|26\nCaitlin|25\nLinda|25\nShelley|25\nSummer|25\nTracy|25\nBronwyn|24\nCarolyn|24\nGemma|24\nJoanna|24\nMaia|24\nMargaret|24\nMonique|24\nSandra|24\nStacey|24\nKirsty|23\nLeanne|23\nMolly|23\nPatricia|23\nPenelope|23\nVicki|23\nZara|23\nBridget|22\nMia|22\nRobyn|22\nStella|22\nTessa|22\nAnita|21\nBrenda|21\nCourtney|21\nErin|21\nEva|21\nIsabelle|21\nJanine|21\nKerry|21\nRochelle|21\nTaylor|21\nAshleigh|20\nAva|20\nBella|20\nChelsea|20\nDenise|20\nDiane|20\nKathleen|20\nMackenzie|20\nMaree|20\nMikayla|20\nPhilippa|20\nRebekah|20\nRuth|20\nAaliyah|19\nAnne|19\nAnnette|19\nDebra|19\nIsla|19\nKylie|19\nNikita|19\nTina|19\nCarol|18\nCasey|18\nLilly|18\nPauline|18\nPoppy|18\nRaewyn|18\nScarlett|18\nSienna|18\nTayla|18\nAlana|17\nBarbara|17\nCheryl|17\nJudith|17\nKimberley|17\nLynda|17\nLynette|17\nPamela|17\nTanya|17\nAnn|16\nAria|16\nBrooklyn|16\nDebbie|16\nJamie|16\nJessie|16\nMadeleine|16\nMillie|16\nRiley|16\nSara|16\nSheryl|16\nAlyssa|15\nAyla|15\nDianne|15\nFaith|15\nFrances|15\nHazel|15\nJan|15\nKirsten|15\nPiper|15\nSofia|15\nYvonne|15\nBelinda|14\nCherie|14\nCrystal|14\nGabrielle|14\nGeorgina|14\nGillian|14\nShona|14\nAddison|13\nJanet|13\nJillian|13\nLayla|13\nMatilda|13\nMaya|13\nMila|13\nOlive|13\nRosemary|13\nViolet|13\nWillow|13\nAlexis|12\nAngel|12\nColleen|12\nDiana|12\nEllie|12\nEvelyn|12\nIvy|12\nJenna|12\nJordan|12\nKay|12\nKeira|12\nLesley|12\nLorraine|12\nLynne|12\nPeyton|12\nAlicia|11\nAnnabelle|11\nAriana|11\nBrianna|11\nBrittany|11\nClaudia|11\nGail|11\nHarper|11\nIndie|11\nIsabel|11\nJanice|11\nJeanette|11\nKrystal|11\nMaureen|11\nMichele|11\nMorgan|11\nNevaeh|11\nNina|11\nShirley|11\nAurora|10\nEvie|10\nFlorence|10\nHeidi|10\nJustine|10\nKelsey|10\nVivienne|10\nAbby|9\nAshlee|9\nBeverley|9\nCaitlyn|9\nDaisy|9\nFreya|9\nHarriet|9\nImogen|9\nLola|9\nPippa|9\nSavannah|9\nThea|9\nAdrienne|8\nCassandra|8\nCharlie|8\nEleanor|8\nEmilia|8\nFrankie|8\nGlenda|8\nJosephine|8\nMichaela|8\nQuinn|8\nSadie|8\nSonya|8\nTara|8\nTiana|8\nZoey|8\nElsie|7\nJocelyn|7\nKaitlyn|7\nLydia|7\nNaomi|7\nParis|7\nTrinity|7\nBillie|6\nCheyenne|6\nHarmony|6\nJill|6\nJodie|6\nJorja|6\nJoy|6\nKaryn|6\nKatelyn|6\nLuna|6\nMya|6\nTegan|6\nAmaia|5\nCarla|5\nElaine|5\nGina|5\nGlenys|5\nJolene|5\nKiara|5\nLucia|5\nTamara|5\nValerie|5\nAda|4\nDorothy|4\nEsther|4\nHarlow|4\nJemma|4\nLois|4\nMadeline|4\nMaisie|4\nManaia|4\nMarilyn|4\nMarion|4\nSonia|4\nAnahera|3\nBailey|3\nCarmen|3\nDestiny|3\nEliza|3\nHaley|3\nHope|3\nJoan|3\nKaia|3\nKaye|3\nKristy|3\nLynley|3\nMaeve|3\nMargot|3\nRosie|3\nShania|3\nSharlene|3\nSheree|3\nVicky|3\nAleisha|2\nAmara|2\nAthena|2\nBonnie|2\nCora|2\nDelilah|2\nEllen|2\nEloise|2\nGabriella|2\nGloria|2\nIrene|2\nIsobel|2\nKhloe|2\nKiri|2\nKora|2\nLynnette|2\nMarley|2\nNadine|2\nNgaire|2\nRhonda|2\nSkye|2\nSkyla|2\nTyla|2\nAbbey|1\nAngelina|1\nAnika|1\nApril|1\nArabella|1\nAroha|1\nBriana|1\nBritney|1\nChantelle|1\nCindy|1\nClara|1\nClare|1\nCleo|1\nDawn|1\nEilish|1\nEliana|1\nElise|1\nGaylene|1\nIndi|1\nIris|1\nJaime|1\nJanette|1\nJean|1\nJodi|1\nKaitlin|1\nKarla|1\nKellie|1\nKyla|1\nLeonie|1\nLibby|1\nLynn|1\nMacKenzie|1\nMarian|1\nMikaela|1\nMonica|1\nNiamh|1\nNikki|1\nPayton|1\nRachelle|1\nSasha|1\nShakira|1\nSinead|1\nSkylar|1\nTori|1\nVirginia|1\nWhitney|1\n\nOnly a single name, Elizabeth, was steadily popular over the 69 year period, occuring among the top 100 names every single year.\nFinally, I said that we don’t need rank table, because we can calculate the ranks from counts. We can do that using advanced SQL commands as well!\nHere we look at 5 most popular names since 2020\nSELECT name, year, count_rank, count\nFROM\n    (SELECT\n        name,\n        year,\n        count,\n        RANK() OVER (PARTITION BY year ORDER BY count DESC) count_rank\n    FROM GirlCounts\n    )\nWHERE count_rank <= 5 AND YEAR >= 2020;\n\n\nClick to unroll\n\nIsla|2020|1|243\nCharlotte|2020|2|222\nAmelia|2020|3|213\nOlivia|2020|4|208\nWillow|2020|5|184\nCharlotte|2021|1|227\nIsla|2021|2|214\nAmelia|2021|3|206\nOlivia|2021|4|185\nAva|2021|5|184\nIsla|2022|1|246\nAmelia|2022|2|210\nCharlotte|2022|3|208\nMila|2022|4|182\nLily|2022|5|180"
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-books",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-books",
    "title": "Learn SQL with me: NZ names",
    "section": "The Books",
    "text": "The Books\nFinally, if you would like to learn more about SQL as I did, here is a small review of books.\nThe best book for beginners is The Manga Guide to Databases. It is the most comprehensive introduction to databases, database design, and SQL. Every other book I have read assumes you already know about databases or SQL, so they often skip over important details.\nNext, I would suggest SQL Antipatterns. It introduces you to some patterns and anti-patterns in SQL and database design. Easy to read, comprehensive and quite practical if you want to get into designing databases.\nThe Seven Databases in Seven Weeks would be next in line. Unlike the previous ones, it doesn’t teach you about database design or SQL tricks. Instead, it is an overview of different database types and products, not just relational databases and not just SQL. It is not an in-depth introduction to SQL or relational databases, so do not make this the first book you read, instead, this book will introduce you to a multitude of other solutions.\nFinally, there is a gold standard Database in Depth. It already assumes that you know quite a lot about databases, and doesn’t talk much about SQL, instead, it introduces language D, the perfect relational language, and talks more about the theory. Unlike other theory books I have read on other topics, this one seems to be quite fluffy. I have read 30 pages and I think that information could be condensed into 10. But then, you don’t need to stare into a single equation with no accompanying explanation for 2 hours to understand it, like in those very dense theory books, because there is a 10-page explanation. So fluffiness might not be disadvantageous."
  },
  {
    "objectID": "posts/sql_nz_names/sql_nz_names.html#the-summary",
    "href": "posts/sql_nz_names/sql_nz_names.html#the-summary",
    "title": "Learn SQL with me: NZ names",
    "section": "The Summary",
    "text": "The Summary\nWe have picked a dataset and gone over some ideas and thoughts on how to convert it into a database. We then implemented the database using SQLite, populated it through R and queried a bunch of interesting data. The database we designed was not the most exciting, since the structure of the dataset was quite simple. Yet, I have learned quite a lot. I hope you enjoyed this journey as I did. I will try to explore the dataset a bit more because I think there is a story hidden inside."
  },
  {
    "objectID": "posts/baseR_AZ/1_introduction.html",
    "href": "posts/baseR_AZ/1_introduction.html",
    "title": "Base R from A to Z: Introduction (1)",
    "section": "",
    "text": "Introduction\nR has quite a rich standard library1, not just to process text, read and work with files, do parallel computing, but also a whole load of statistical functions, including simple neural networks, additive models, survival analysis, and three whole packages for plotting and graphics (graphics for base graphics, grid, and lattice). You can read about all functions in the R’s standard library in the R reference manual.\nThe disadvantage is that while R has a very large standard library, it doesn’t use namespaces. Don’t get me wrong, R has namespaces. Every package has a namespace. And R comes with a bunch of preinstalled packages. But while some specialized statistical functions are in aptly named packages (survival for survival analysis), often a group of unrelated functions are grouped into a single namespace. This presents a significant barrier when it comes to the discoverability of these functions. For instance, consider Python. If you want to work with paths, you know that the functions will be in the os.path module or in the pathlib module, if you want to go for an object-oriented way of handling paths. Additionally, Python’s documentation groups functions according to their usage. Compare this to the R’s reference manual linked above. So if you want to, for instance, know all the functions for text parsing, well good luck. You will have to do a lot of contextualized searches through R’s help system or find a book that does this for you. But while there are books about some popular user-created packages, for instance, the R markdown book, or books that serve as an in-depth exploration of R, such as Advanced R or R packages, there is no in-depth exploration of functions available in base R. This often means that a lot of people will keep reinventing wheels or coming up with complicated solutions requiring one or even multiple packages when there is a more performant one-liner in base R available.\nThe purpose of this series is to explore functions in base R and later perhaps to create a book that will serve as additional documentation of functionalities available in base R.\n\n\nPreinstalled packages\nR comes with a number of preinstalled packages, they are labelled as base and recommended:\n\npackages = installed.packages() |>\n    as.data.frame() |>\n    subset(select=c(\"Package\", \"Priority\")) |>\n    unique() |>\n    split(formula(\"~Priority\"))\nsapply(packages, nrow)\n\n       base recommended \n         14          15 \n\n\nThe 14 base packages are usually the main workhorse of R, while the 15 recommended packages are predominantly of statistical nature. Do not expect the latest, fastest and most feature-full implementation of them, but it also means that if you need something like k-nearest-neighbours, you will find it in the R standard library, which is something that is not typically true for most programming languages.\nBecause of this, the packages have quite a variable number of objects. Here we don’t count only functions, but also included example datasets or pre-set variables. For example T is an alias for TRUE, but you can easily change it such as by setting T=FALSE. So please don’t use T in your scripts, interactive usage only.\nBefore we show the number of objects in each package, we define some helper functions, that way the code will be more readable.\n\n# get object names from a package  \ngetObjects = function(name, all=TRUE){\n    getNamespace(name) |> ls(all.names=all)\n    }\n\n# count the number of objects in a package\ncountObjects = function(name, all=TRUE){\n    getObjects(name, all=all) |> length()\n    }\n\n# apply the countObjects on the `packages` objects defined above\nn_objects = sapply(packages, function(x){\n    x[,1] |> sapply(countObjects) |> sort(decreasing=TRUE)\n    })\nn_objects\n\n$base\n     base     stats      grid   methods     tools     utils     tcltk  compiler \n     1370      1134       872       761       733       529       313       289 \ngrDevices  graphics  parallel   splines    stats4  datasets \n      254       170       145        50        30         3 \n\n$recommended\n    Matrix       nlme       mgcv   survival    lattice       MASS    cluster \n       996        607        495        421        289        232         91 \n codetools       boot    spatial      rpart    foreign       nnet      class \n        89         84         55         51         42         41         29 \nKernSmooth \n        27 \n\n\nFor the packages labelled as base, the base package leads with 1370 objects. The majority of common operations are implemented in this package, from file-system operations, and text-parsing functions, but also mathematical functions like min, mean or set operations. The second largest package is stats, which implements a large number of mathematical and statistical functions. The bread and butter statistical functions like t.test, anova, lm or a general-purpose optimization algorithm optim or functions to work with time-series data are all included in this package. The third largest package is the grid package with 872 objects. grid is one of the alternatives to base graphics, which are implemented in the graphics package. Surprisingly, the graphics package has only 170 objects. Outside of base, stats, tools and utils, the packages starts to be more specialized and also smaller. The packages utils and especially tools are already supposed to be specialized for making packages, but since making packages requires a lot of tooling, and this tooling often has quite a lot of utility, you might occasionally use functions from tools. utils on the other hand has kind of everything, from functions to make packages, download packages, spellchecker, but also functions like help, head, read.table. Classical if you don’t know where to put it, put it into utils.\nIf we look at the packages labelled as recommended, the largest package is the Matrix package, which is the third overall package by size out of preinstalled packages. The Matrix package implements several kinds of sparse matrices and operations on them. This is very important in linear algebra and statistics, as the solution of many statistical models often relies on eigenvalues.\n\nExported functions\nYou might have noticed that I have shown objects using ls(). This way, all objects, whether they are exported or not, are counted. After all, I don’t remember reading about 145 functions in the parallel documentation, so something is off.\nIf we look only at exported objects, the situation would be like this:\n\nn_exported_objects = sapply(packages, function(x){\n    x[,1] |> sapply(\\(y){\n        getNamespaceExports(y) |> length()\n        }) |> sort(decreasing=TRUE)\n    })\nn_exported_objects\n\n$base\n     base     stats   methods     tcltk     utils      grid grDevices     tools \n     1370       456       371       269       221       212       119       119 \n graphics  parallel    stats4   splines  compiler  datasets \n       88        33        28        13         9         0 \n\n$recommended\n    Matrix       mgcv    lattice       nlme       MASS   survival       boot \n       367        182        144        109         78         77         36 \n   spatial    cluster  codetools    foreign      class      rpart KernSmooth \n        25         24         19         17         15         14          7 \n      nnet \n         7 \n\n\nWe can see that the number of objects changes drastically, although the base package remained unaltered. Interestingly, the package datasets doesn’t have a single exported object. This is because datasets consist only of datasets, which are loaded lazily. That is until you use the dataset, it does not occupy the computer memory.\nNow, let’s move to the core of the series, the base package.\n\n\n\nBase R\nWe have explored the number of objects across preinstalled packages, but how many functions are in the base package? The core of base R?\n\n# You can see a similar code in ?Filter examples\nfuns = Filter(is.function, sapply(\n    ls(baseenv(), all.names=TRUE), get, baseenv()\n    ))\nlength(funs)\n\n[1] 1325\n\n\nQuite a lot, 1325 functions. However, a great deal of them are S3 methods. For instance, there are 36 methods just for the S3 generic print.\n\ngrep(\"print.\", baseenv() |> ls(all.names=TRUE),\n    value=TRUE, fixed=TRUE) |> length()\n\n[1] 36\n\n\nThese methods are very important to seamlessly work with different S3 classes. After all, no one wants to call print.foo(x) and print.bar(y), when we can just type print(z). This reduces typing for sure, but also decreases mental overload. In fact, many R users do not know about S3 system, but the dispatch of various methods still work like magic. But enough about S3. For the purpose of this exercise, these are not very interesting. Maybe in the future, we will explore what kind of S3 classes are defined in base R.\nTo filter the S3 methods, we can use isS3method. The only issue is that this function fails for any object starting with a dot. Bummer. Objects starting with a dot are typically considered hidden objects, which should not be used unless you know what you are doing (such as .C or .Call, which are important tools when writing packages).\n\n# this would fail:\n# isS3method(\".C\")\n\nvisible = grep(\"^\\\\.\", names(funs), value=TRUE, invert=TRUE)\n\nnormal = Filter(Negate(isS3method), visible)\nnormal |> length()\n\n[1] 865\n\n\nThis means that to explore all the functions in base package, we need to go through 865 functions.\nThere is a small caveat we have talked about before. ls() does not distinguish whether the functions are or are not exported. Luckily for us, we saw that all the functions in the base package are exported. But just to be sure:\n\n# helper, take a string instead of a function object\nis_function = function(name, env=baseenv()){\n    f = get(name, envir=env)\n    is.function(f)\n    }\n\nnormal = getNamespaceExports(\"base\") |>\n    Filter(f=is_function) |>\n    grep(pattern=\"^\\\\.\", value=TRUE, invert=TRUE) |>\n    Filter(f=Negate(isS3method)) |> sort()\nnormal |> length()\n\n[1] 865\n\n\nUsing slightly different calls, we have arrived at the same number. Great!\n\n\nWhat can you expect next?\nIn the following part of the series, we will start going through the functions alphabetically. Although when we will find a group of similar or related functions, we will describe them together, such as sub and gsub.\nWe will start with the special symbols or operators, make a small segway about different types of functions in R, like .Primitive, .Internal, and we will have to talk a bit more about the generics.\nI hope that you have found this small exploration of the preinstalled packages interesting and that you are as excited as me about continuing in this series.\n\n\nList of functions in the base package\nWe will end with a list of all functions that we will go through in this series:\n\n\nClick to unroll\n\n\n\n  [1] \"-\"                              \":\"                             \n  [3] \"::\"                             \":::\"                           \n  [5] \"!\"                              \"!=\"                            \n  [7] \"(\"                              \"[\"                             \n  [9] \"[[\"                             \"[[<-\"                          \n [11] \"[<-\"                            \"{\"                             \n [13] \"@\"                              \"@<-\"                           \n [15] \"*\"                              \"/\"                             \n [17] \"&\"                              \"&&\"                            \n [19] \"%*%\"                            \"%/%\"                           \n [21] \"%%\"                             \"%in%\"                          \n [23] \"%o%\"                            \"%x%\"                           \n [25] \"^\"                              \"+\"                             \n [27] \"<\"                              \"<-\"                            \n [29] \"<<-\"                            \"<=\"                            \n [31] \"=\"                              \"==\"                            \n [33] \">\"                              \">=\"                            \n [35] \"|\"                              \"||\"                            \n [37] \"~\"                              \"$\"                             \n [39] \"$<-\"                            \"abbreviate\"                    \n [41] \"abs\"                            \"acos\"                          \n [43] \"acosh\"                          \"activeBindingFunction\"         \n [45] \"addNA\"                          \"addTaskCallback\"               \n [47] \"agrep\"                          \"agrepl\"                        \n [49] \"alist\"                          \"all\"                           \n [51] \"all.equal\"                      \"all.names\"                     \n [53] \"all.vars\"                       \"allowInterrupts\"               \n [55] \"any\"                            \"anyDuplicated\"                 \n [57] \"anyNA\"                          \"aperm\"                         \n [59] \"append\"                         \"apply\"                         \n [61] \"Arg\"                            \"args\"                          \n [63] \"array\"                          \"arrayInd\"                      \n [65] \"as.array\"                       \"as.call\"                       \n [67] \"as.character\"                   \"as.complex\"                    \n [69] \"as.data.frame\"                  \"as.Date\"                       \n [71] \"as.difftime\"                    \"as.double\"                     \n [73] \"as.environment\"                 \"as.expression\"                 \n [75] \"as.factor\"                      \"as.function\"                   \n [77] \"as.hexmode\"                     \"as.integer\"                    \n [79] \"as.list\"                        \"as.logical\"                    \n [81] \"as.matrix\"                      \"as.name\"                       \n [83] \"as.null\"                        \"as.numeric\"                    \n [85] \"as.numeric_version\"             \"as.octmode\"                    \n [87] \"as.ordered\"                     \"as.package_version\"            \n [89] \"as.pairlist\"                    \"as.POSIXct\"                    \n [91] \"as.POSIXlt\"                     \"as.qr\"                         \n [93] \"as.raw\"                         \"as.single\"                     \n [95] \"as.symbol\"                      \"as.table\"                      \n [97] \"as.vector\"                      \"asin\"                          \n [99] \"asinh\"                          \"asNamespace\"                   \n[101] \"asplit\"                         \"asS3\"                          \n[103] \"asS4\"                           \"assign\"                        \n[105] \"atan\"                           \"atan2\"                         \n[107] \"atanh\"                          \"attach\"                        \n[109] \"attachNamespace\"                \"attr\"                          \n[111] \"attr.all.equal\"                 \"attr<-\"                        \n[113] \"attributes\"                     \"attributes<-\"                  \n[115] \"autoload\"                       \"autoloader\"                    \n[117] \"backsolve\"                      \"baseenv\"                       \n[119] \"basename\"                       \"besselI\"                       \n[121] \"besselJ\"                        \"besselK\"                       \n[123] \"besselY\"                        \"beta\"                          \n[125] \"bindingIsActive\"                \"bindingIsLocked\"               \n[127] \"bindtextdomain\"                 \"bitwAnd\"                       \n[129] \"bitwNot\"                        \"bitwOr\"                        \n[131] \"bitwShiftL\"                     \"bitwShiftR\"                    \n[133] \"bitwXor\"                        \"body\"                          \n[135] \"body<-\"                         \"bquote\"                        \n[137] \"break\"                          \"browser\"                       \n[139] \"browserCondition\"               \"browserSetDebug\"               \n[141] \"browserText\"                    \"builtins\"                      \n[143] \"by\"                             \"bzfile\"                        \n[145] \"c\"                              \"call\"                          \n[147] \"callCC\"                         \"capabilities\"                  \n[149] \"casefold\"                       \"cat\"                           \n[151] \"cbind\"                          \"ceiling\"                       \n[153] \"char.expand\"                    \"character\"                     \n[155] \"charmatch\"                      \"charToRaw\"                     \n[157] \"chartr\"                         \"check_tzones\"                  \n[159] \"chkDots\"                        \"chol\"                          \n[161] \"chol2inv\"                       \"choose\"                        \n[163] \"class\"                          \"class<-\"                       \n[165] \"clearPushBack\"                  \"close\"                         \n[167] \"closeAllConnections\"            \"col\"                           \n[169] \"colMeans\"                       \"colnames\"                      \n[171] \"colnames<-\"                     \"colSums\"                       \n[173] \"commandArgs\"                    \"comment\"                       \n[175] \"comment<-\"                      \"complex\"                       \n[177] \"computeRestarts\"                \"conditionCall\"                 \n[179] \"conditionMessage\"               \"conflictRules\"                 \n[181] \"conflicts\"                      \"Conj\"                          \n[183] \"contributors\"                   \"cos\"                           \n[185] \"cosh\"                           \"cospi\"                         \n[187] \"crossprod\"                      \"Cstack_info\"                   \n[189] \"cummax\"                         \"cummin\"                        \n[191] \"cumprod\"                        \"cumsum\"                        \n[193] \"curlGetHeaders\"                 \"cut\"                           \n[195] \"data.class\"                     \"data.frame\"                    \n[197] \"data.matrix\"                    \"date\"                          \n[199] \"debug\"                          \"debuggingState\"                \n[201] \"debugonce\"                      \"default.stringsAsFactors\"      \n[203] \"delayedAssign\"                  \"deparse\"                       \n[205] \"deparse1\"                       \"det\"                           \n[207] \"detach\"                         \"determinant\"                   \n[209] \"dget\"                           \"diag\"                          \n[211] \"diag<-\"                         \"diff\"                          \n[213] \"difftime\"                       \"digamma\"                       \n[215] \"dim\"                            \"dim<-\"                         \n[217] \"dimnames\"                       \"dimnames<-\"                    \n[219] \"dir\"                            \"dir.create\"                    \n[221] \"dir.exists\"                     \"dirname\"                       \n[223] \"do.call\"                        \"dontCheck\"                     \n[225] \"double\"                         \"dput\"                          \n[227] \"dQuote\"                         \"drop\"                          \n[229] \"droplevels\"                     \"dump\"                          \n[231] \"duplicated\"                     \"dyn.load\"                      \n[233] \"dyn.unload\"                     \"dynGet\"                        \n[235] \"eapply\"                         \"eigen\"                         \n[237] \"emptyenv\"                       \"enc2native\"                    \n[239] \"enc2utf8\"                       \"encodeString\"                  \n[241] \"Encoding\"                       \"Encoding<-\"                    \n[243] \"endsWith\"                       \"enquote\"                       \n[245] \"env.profile\"                    \"environment\"                   \n[247] \"environment<-\"                  \"environmentIsLocked\"           \n[249] \"environmentName\"                \"errorCondition\"                \n[251] \"eval\"                           \"eval.parent\"                   \n[253] \"evalq\"                          \"exists\"                        \n[255] \"exp\"                            \"expand.grid\"                   \n[257] \"expm1\"                          \"expression\"                    \n[259] \"extSoftVersion\"                 \"factor\"                        \n[261] \"factorial\"                      \"fifo\"                          \n[263] \"file\"                           \"file.access\"                   \n[265] \"file.append\"                    \"file.choose\"                   \n[267] \"file.copy\"                      \"file.create\"                   \n[269] \"file.exists\"                    \"file.info\"                     \n[271] \"file.link\"                      \"file.mode\"                     \n[273] \"file.mtime\"                     \"file.path\"                     \n[275] \"file.remove\"                    \"file.rename\"                   \n[277] \"file.show\"                      \"file.size\"                     \n[279] \"file.symlink\"                   \"Filter\"                        \n[281] \"Find\"                           \"find.package\"                  \n[283] \"findInterval\"                   \"findPackageEnv\"                \n[285] \"findRestart\"                    \"floor\"                         \n[287] \"flush\"                          \"for\"                           \n[289] \"force\"                          \"forceAndCall\"                  \n[291] \"formals\"                        \"formals<-\"                     \n[293] \"format\"                         \"format.info\"                   \n[295] \"format.pval\"                    \"formatC\"                       \n[297] \"formatDL\"                       \"forwardsolve\"                  \n[299] \"function\"                       \"gamma\"                         \n[301] \"gc\"                             \"gc.time\"                       \n[303] \"gcinfo\"                         \"gctorture\"                     \n[305] \"gctorture2\"                     \"get\"                           \n[307] \"get0\"                           \"getAllConnections\"             \n[309] \"getCallingDLL\"                  \"getCallingDLLe\"                \n[311] \"getConnection\"                  \"getDLLRegisteredRoutines\"      \n[313] \"getElement\"                     \"geterrmessage\"                 \n[315] \"getExportedValue\"               \"getHook\"                       \n[317] \"getLoadedDLLs\"                  \"getNamespace\"                  \n[319] \"getNamespaceExports\"            \"getNamespaceImports\"           \n[321] \"getNamespaceInfo\"               \"getNamespaceName\"              \n[323] \"getNamespaceUsers\"              \"getNamespaceVersion\"           \n[325] \"getNativeSymbolInfo\"            \"getOption\"                     \n[327] \"getRversion\"                    \"getSrcLines\"                   \n[329] \"getTaskCallbackNames\"           \"gettext\"                       \n[331] \"gettextf\"                       \"getwd\"                         \n[333] \"gl\"                             \"globalCallingHandlers\"         \n[335] \"globalenv\"                      \"gregexec\"                      \n[337] \"gregexpr\"                       \"grep\"                          \n[339] \"grepl\"                          \"grepRaw\"                       \n[341] \"grouping\"                       \"gsub\"                          \n[343] \"gzcon\"                          \"gzfile\"                        \n[345] \"I\"                              \"iconv\"                         \n[347] \"iconvlist\"                      \"icuGetCollate\"                 \n[349] \"icuSetCollate\"                  \"identical\"                     \n[351] \"identity\"                       \"if\"                            \n[353] \"ifelse\"                         \"Im\"                            \n[355] \"importIntoEnv\"                  \"infoRDS\"                       \n[357] \"inherits\"                       \"integer\"                       \n[359] \"interaction\"                    \"interactive\"                   \n[361] \"intersect\"                      \"intToBits\"                     \n[363] \"intToUtf8\"                      \"inverse.rle\"                   \n[365] \"invisible\"                      \"invokeRestart\"                 \n[367] \"invokeRestartInteractively\"     \"is.array\"                      \n[369] \"is.atomic\"                      \"is.call\"                       \n[371] \"is.character\"                   \"is.complex\"                    \n[373] \"is.data.frame\"                  \"is.double\"                     \n[375] \"is.element\"                     \"is.environment\"                \n[377] \"is.expression\"                  \"is.factor\"                     \n[379] \"is.finite\"                      \"is.function\"                   \n[381] \"is.infinite\"                    \"is.integer\"                    \n[383] \"is.language\"                    \"is.list\"                       \n[385] \"is.loaded\"                      \"is.logical\"                    \n[387] \"is.matrix\"                      \"is.na\"                         \n[389] \"is.na<-\"                        \"is.name\"                       \n[391] \"is.nan\"                         \"is.null\"                       \n[393] \"is.numeric\"                     \"is.numeric_version\"            \n[395] \"is.object\"                      \"is.ordered\"                    \n[397] \"is.package_version\"             \"is.pairlist\"                   \n[399] \"is.primitive\"                   \"is.qr\"                         \n[401] \"is.R\"                           \"is.raw\"                        \n[403] \"is.recursive\"                   \"is.single\"                     \n[405] \"is.symbol\"                      \"is.table\"                      \n[407] \"is.unsorted\"                    \"is.vector\"                     \n[409] \"isa\"                            \"isatty\"                        \n[411] \"isBaseNamespace\"                \"isdebugged\"                    \n[413] \"isFALSE\"                        \"isIncomplete\"                  \n[415] \"isNamespace\"                    \"isNamespaceLoaded\"             \n[417] \"ISOdate\"                        \"ISOdatetime\"                   \n[419] \"isOpen\"                         \"isRestart\"                     \n[421] \"isS4\"                           \"isSeekable\"                    \n[423] \"isSymmetric\"                    \"isTRUE\"                        \n[425] \"jitter\"                         \"julian\"                        \n[427] \"kappa\"                          \"kronecker\"                     \n[429] \"l10n_info\"                      \"La_library\"                    \n[431] \"La_version\"                     \"La.svd\"                        \n[433] \"labels\"                         \"lapply\"                        \n[435] \"lazyLoad\"                       \"lazyLoadDBexec\"                \n[437] \"lazyLoadDBfetch\"                \"lbeta\"                         \n[439] \"lchoose\"                        \"length\"                        \n[441] \"length<-\"                       \"lengths\"                       \n[443] \"levels\"                         \"levels<-\"                      \n[445] \"lfactorial\"                     \"lgamma\"                        \n[447] \"libcurlVersion\"                 \"library\"                       \n[449] \"library.dynam\"                  \"library.dynam.unload\"          \n[451] \"licence\"                        \"license\"                       \n[453] \"list\"                           \"list.dirs\"                     \n[455] \"list.files\"                     \"list2DF\"                       \n[457] \"list2env\"                       \"load\"                          \n[459] \"loadedNamespaces\"               \"loadingNamespaceInfo\"          \n[461] \"loadNamespace\"                  \"local\"                         \n[463] \"lockBinding\"                    \"lockEnvironment\"               \n[465] \"log\"                            \"log10\"                         \n[467] \"log1p\"                          \"log2\"                          \n[469] \"logb\"                           \"logical\"                       \n[471] \"lower.tri\"                      \"ls\"                            \n[473] \"make.names\"                     \"make.unique\"                   \n[475] \"makeActiveBinding\"              \"Map\"                           \n[477] \"mapply\"                         \"margin.table\"                  \n[479] \"marginSums\"                     \"mat.or.vec\"                    \n[481] \"match\"                          \"match.arg\"                     \n[483] \"match.call\"                     \"match.fun\"                     \n[485] \"matrix\"                         \"max\"                           \n[487] \"max.col\"                        \"mean\"                          \n[489] \"mem.maxNSize\"                   \"mem.maxVSize\"                  \n[491] \"memCompress\"                    \"memDecompress\"                 \n[493] \"memory.profile\"                 \"merge\"                         \n[495] \"message\"                        \"mget\"                          \n[497] \"min\"                            \"missing\"                       \n[499] \"Mod\"                            \"mode\"                          \n[501] \"mode<-\"                         \"months\"                        \n[503] \"mostattributes<-\"               \"names\"                         \n[505] \"names<-\"                        \"namespaceExport\"               \n[507] \"namespaceImport\"                \"namespaceImportClasses\"        \n[509] \"namespaceImportFrom\"            \"namespaceImportMethods\"        \n[511] \"nargs\"                          \"nchar\"                         \n[513] \"ncol\"                           \"NCOL\"                          \n[515] \"Negate\"                         \"new.env\"                       \n[517] \"next\"                           \"NextMethod\"                    \n[519] \"ngettext\"                       \"nlevels\"                       \n[521] \"noquote\"                        \"norm\"                          \n[523] \"normalizePath\"                  \"nrow\"                          \n[525] \"NROW\"                           \"nullfile\"                      \n[527] \"numeric\"                        \"numeric_version\"               \n[529] \"numToBits\"                      \"numToInts\"                     \n[531] \"nzchar\"                         \"objects\"                       \n[533] \"oldClass\"                       \"oldClass<-\"                    \n[535] \"OlsonNames\"                     \"on.exit\"                       \n[537] \"open\"                           \"options\"                       \n[539] \"order\"                          \"ordered\"                       \n[541] \"outer\"                          \"package_version\"               \n[543] \"packageEvent\"                   \"packageHasNamespace\"           \n[545] \"packageNotFoundError\"           \"packageStartupMessage\"         \n[547] \"packBits\"                       \"pairlist\"                      \n[549] \"parent.env\"                     \"parent.env<-\"                  \n[551] \"parent.frame\"                   \"parse\"                         \n[553] \"parseNamespaceFile\"             \"paste\"                         \n[555] \"paste0\"                         \"path.expand\"                   \n[557] \"path.package\"                   \"pcre_config\"                   \n[559] \"pipe\"                           \"plot\"                          \n[561] \"pmatch\"                         \"pmax\"                          \n[563] \"pmax.int\"                       \"pmin\"                          \n[565] \"pmin.int\"                       \"polyroot\"                      \n[567] \"pos.to.env\"                     \"Position\"                      \n[569] \"pretty\"                         \"prettyNum\"                     \n[571] \"print\"                          \"prmatrix\"                      \n[573] \"proc.time\"                      \"prod\"                          \n[575] \"prop.table\"                     \"proportions\"                   \n[577] \"provideDimnames\"                \"psigamma\"                      \n[579] \"pushBack\"                       \"pushBackLength\"                \n[581] \"q\"                              \"qr\"                            \n[583] \"qr.coef\"                        \"qr.fitted\"                     \n[585] \"qr.Q\"                           \"qr.qty\"                        \n[587] \"qr.qy\"                          \"qr.R\"                          \n[589] \"qr.resid\"                       \"qr.solve\"                      \n[591] \"qr.X\"                           \"quarters\"                      \n[593] \"quit\"                           \"quote\"                         \n[595] \"R_system_version\"               \"R.home\"                        \n[597] \"R.Version\"                      \"range\"                         \n[599] \"rank\"                           \"rapply\"                        \n[601] \"raw\"                            \"rawConnection\"                 \n[603] \"rawConnectionValue\"             \"rawShift\"                      \n[605] \"rawToBits\"                      \"rawToChar\"                     \n[607] \"rbind\"                          \"rcond\"                         \n[609] \"Re\"                             \"read.dcf\"                      \n[611] \"readBin\"                        \"readChar\"                      \n[613] \"readline\"                       \"readLines\"                     \n[615] \"readRDS\"                        \"readRenviron\"                  \n[617] \"Recall\"                         \"Reduce\"                        \n[619] \"reg.finalizer\"                  \"regexec\"                       \n[621] \"regexpr\"                        \"registerS3method\"              \n[623] \"registerS3methods\"              \"regmatches\"                    \n[625] \"regmatches<-\"                   \"remove\"                        \n[627] \"removeTaskCallback\"             \"rep\"                           \n[629] \"rep_len\"                        \"rep.int\"                       \n[631] \"repeat\"                         \"replace\"                       \n[633] \"replicate\"                      \"require\"                       \n[635] \"requireNamespace\"               \"restartDescription\"            \n[637] \"restartFormals\"                 \"retracemem\"                    \n[639] \"return\"                         \"returnValue\"                   \n[641] \"rev\"                            \"rle\"                           \n[643] \"rm\"                             \"RNGkind\"                       \n[645] \"RNGversion\"                     \"round\"                         \n[647] \"row\"                            \"row.names\"                     \n[649] \"row.names<-\"                    \"rowMeans\"                      \n[651] \"rownames\"                       \"rownames<-\"                    \n[653] \"rowsum\"                         \"rowSums\"                       \n[655] \"sample\"                         \"sample.int\"                    \n[657] \"sapply\"                         \"save\"                          \n[659] \"save.image\"                     \"saveRDS\"                       \n[661] \"scale\"                          \"scan\"                          \n[663] \"search\"                         \"searchpaths\"                   \n[665] \"seek\"                           \"seq\"                           \n[667] \"seq_along\"                      \"seq_len\"                       \n[669] \"seq.int\"                        \"sequence\"                      \n[671] \"serialize\"                      \"serverSocket\"                  \n[673] \"set.seed\"                       \"setdiff\"                       \n[675] \"setequal\"                       \"setHook\"                       \n[677] \"setNamespaceInfo\"               \"setSessionTimeLimit\"           \n[679] \"setTimeLimit\"                   \"setwd\"                         \n[681] \"showConnections\"                \"shQuote\"                       \n[683] \"sign\"                           \"signalCondition\"               \n[685] \"signif\"                         \"simpleCondition\"               \n[687] \"simpleError\"                    \"simpleMessage\"                 \n[689] \"simpleWarning\"                  \"simplify2array\"                \n[691] \"sin\"                            \"single\"                        \n[693] \"sinh\"                           \"sink\"                          \n[695] \"sink.number\"                    \"sinpi\"                         \n[697] \"slice.index\"                    \"socketAccept\"                  \n[699] \"socketConnection\"               \"socketSelect\"                  \n[701] \"socketTimeout\"                  \"solve\"                         \n[703] \"sort\"                           \"sort.int\"                      \n[705] \"sort.list\"                      \"source\"                        \n[707] \"split\"                          \"split<-\"                       \n[709] \"sprintf\"                        \"sqrt\"                          \n[711] \"sQuote\"                         \"srcfile\"                       \n[713] \"srcfilealias\"                   \"srcfilecopy\"                   \n[715] \"srcref\"                         \"standardGeneric\"               \n[717] \"startsWith\"                     \"stderr\"                        \n[719] \"stdin\"                          \"stdout\"                        \n[721] \"stop\"                           \"stopifnot\"                     \n[723] \"storage.mode\"                   \"storage.mode<-\"                \n[725] \"str2expression\"                 \"str2lang\"                      \n[727] \"strftime\"                       \"strptime\"                      \n[729] \"strrep\"                         \"strsplit\"                      \n[731] \"strtoi\"                         \"strtrim\"                       \n[733] \"structure\"                      \"strwrap\"                       \n[735] \"sub\"                            \"subset\"                        \n[737] \"substitute\"                     \"substr\"                        \n[739] \"substr<-\"                       \"substring\"                     \n[741] \"substring<-\"                    \"sum\"                           \n[743] \"summary\"                        \"suppressMessages\"              \n[745] \"suppressPackageStartupMessages\" \"suppressWarnings\"              \n[747] \"suspendInterrupts\"              \"svd\"                           \n[749] \"sweep\"                          \"switch\"                        \n[751] \"sys.call\"                       \"sys.calls\"                     \n[753] \"Sys.chmod\"                      \"Sys.Date\"                      \n[755] \"sys.frame\"                      \"sys.frames\"                    \n[757] \"sys.function\"                   \"Sys.getenv\"                    \n[759] \"Sys.getlocale\"                  \"Sys.getpid\"                    \n[761] \"Sys.glob\"                       \"Sys.info\"                      \n[763] \"sys.load.image\"                 \"Sys.localeconv\"                \n[765] \"sys.nframe\"                     \"sys.on.exit\"                   \n[767] \"sys.parent\"                     \"sys.parents\"                   \n[769] \"Sys.readlink\"                   \"sys.save.image\"                \n[771] \"Sys.setenv\"                     \"Sys.setFileTime\"               \n[773] \"Sys.setlocale\"                  \"Sys.sleep\"                     \n[775] \"sys.source\"                     \"sys.status\"                    \n[777] \"Sys.time\"                       \"Sys.timezone\"                  \n[779] \"Sys.umask\"                      \"Sys.unsetenv\"                  \n[781] \"Sys.which\"                      \"system\"                        \n[783] \"system.file\"                    \"system.time\"                   \n[785] \"system2\"                        \"t\"                             \n[787] \"table\"                          \"tabulate\"                      \n[789] \"tan\"                            \"tanh\"                          \n[791] \"tanpi\"                          \"tapply\"                        \n[793] \"taskCallbackManager\"            \"tcrossprod\"                    \n[795] \"tempdir\"                        \"tempfile\"                      \n[797] \"textConnection\"                 \"textConnectionValue\"           \n[799] \"tolower\"                        \"topenv\"                        \n[801] \"toString\"                       \"toupper\"                       \n[803] \"trace\"                          \"traceback\"                     \n[805] \"tracemem\"                       \"tracingState\"                  \n[807] \"transform\"                      \"trigamma\"                      \n[809] \"trimws\"                         \"trunc\"                         \n[811] \"truncate\"                       \"try\"                           \n[813] \"tryCatch\"                       \"tryInvokeRestart\"              \n[815] \"typeof\"                         \"unclass\"                       \n[817] \"undebug\"                        \"union\"                         \n[819] \"unique\"                         \"units\"                         \n[821] \"units<-\"                        \"unix.time\"                     \n[823] \"unlink\"                         \"unlist\"                        \n[825] \"unloadNamespace\"                \"unlockBinding\"                 \n[827] \"unname\"                         \"unserialize\"                   \n[829] \"unsplit\"                        \"untrace\"                       \n[831] \"untracemem\"                     \"unz\"                           \n[833] \"upper.tri\"                      \"url\"                           \n[835] \"UseMethod\"                      \"utf8ToInt\"                     \n[837] \"validEnc\"                       \"validUTF8\"                     \n[839] \"vapply\"                         \"vector\"                        \n[841] \"Vectorize\"                      \"warning\"                       \n[843] \"warningCondition\"               \"warnings\"                      \n[845] \"weekdays\"                       \"which\"                         \n[847] \"which.max\"                      \"which.min\"                     \n[849] \"while\"                          \"with\"                          \n[851] \"withAutoprint\"                  \"withCallingHandlers\"           \n[853] \"within\"                         \"withRestarts\"                  \n[855] \"withVisible\"                    \"write\"                         \n[857] \"write.dcf\"                      \"writeBin\"                      \n[859] \"writeChar\"                      \"writeLines\"                    \n[861] \"xor\"                            \"xpdrows.data.frame\"            \n[863] \"xtfrm\"                          \"xzfile\"                        \n[865] \"zapsmall\"                      \n\n\n\n\n\n\n\n\nFootnotes\n\n\nFor the definition of a standard library, see: https://en.wikipedia.org/wiki/Standard_library↩︎"
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html",
    "href": "posts/baseR_AZ/3_operators.html",
    "title": "Base R from A to Z: Operators (3)",
    "section": "",
    "text": "In the third part of the series about base R, we will talk about operators. As we have mentioned in the previous part, operators are construct similar to functions, but with special syntax or semantics. While you can call them as a functions, and there are instances where you want to do that, normally you call them in a special way called infix notation.\n\n\n\n\n\n\nInfix, prefix and postfix\n\n\n\nMost of us are used to the classical infix notation, such as 3 + 5. However, in some older programming languages, there is also a prefix notation + 3 5 and postfix notation 3 5 +. These can be efficiently parsed using a stack, and do not require operator precedence.\nTechnically, R contains a traces of prefix notation in the form \"+\"(3,5) (or in fact, any functional call), but unlike in the typical prefix or postfix languages, the parentheses are required. Additionally, ! is unary, and - and + have unary form, so they can be considered prefix, such as -8 or !a.\nFor more information, see infix, prefix and postfix on Wikipedia.\n\n\nR offers a multitude of operators and a way to define new operators through the %any% notation. Operators can be divided into these groups:\n\nArithmetic operators\n+, -, *, /, ^, %%, %/%\nLogical operators\n!, &, &&, |, ||\nRelational operatos\n<, >, <=, >=, ==, !=\nSubsetting operators\n[, [[, @, $\nAssignment operators\n<-, <<-, =, [<-, [[<-, @<-, $<-\nMatrix operators\n%*%, %o%, %x%\nSpecial operator\n%anything%\nMatching operator\n%in%\nSequence operator\n:\nOperators in formula: ~, :, %in%\nNamespace access: ::, :::\nParentheses and braces\n(, {\n\nWe will talk about Arithmetic, Logical, Relational, Subsetting, Assigment and Matrix operators, as well as the special operator %anything%. Matching operator is just a shorthand for the match() function, so we will leave it for later. The sequence operator : is a primitive for performance (and parsing) reasons, but we will talk about it together with other sequence-generating functions. The :: and ::: are quite complex, so we will talk about them when we go deeper into environments, namespaces and package access, and the ( and { are language features rather than operators or functions, so we skip them for later. Finally, the ? operator is not part of the base, but is in utils."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#operator-precedence",
    "href": "posts/baseR_AZ/3_operators.html#operator-precedence",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Operator precedence",
    "text": "Operator precedence\nFrom basic mathematics, we are used to the idea that multiplication precedes addition, so 3 + 5 * 2 is interpreted as 3 + (5 * 2) without having to use parentheses. These rules are called operator precedence. Here I am reproducing the list from the ?Syntax help command.\nFor listed operators, precedence goes from highest (evaluated first) to lowest. Operators with the same precedence are evaluated in the order they are encountered.\n\n::, :::\n$, @\n[, [[\n^\n-, + in their unary form (-3, +5)\n:\n%any%, |> (base R pipe)\n*, /\n+, - in their binary form (3+5)\n<, >, <=, ==, !=\n!\n&, &&\n|, ||\n~\n->, ->>\n<-, <<-\n=\n?\n\nNow for some interesting consequences. With ^ having such high precedence, -a^2 is interpeted as -(a^2) instead of (-a)^2, but then -1:3 is interpeted as (-1):3 and not -(1:3).\nThe pipe |> has high precedence, which mean you can’t do a + 2 |> ..., because it is interpeted as a + (2 |> ...). This bites me all the time, when I just want to do some simple division or addition inside pipes.\nFinally = has lower precedence than <-. This shouldn’t be an issue since you should use either = or <- as your assignment operator.\nThe takeway is that you should not rely on common sense your knowledge of operator precedence rules, but use parentheses to make operations as much explicit as possible."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#arithmetic-operators",
    "href": "posts/baseR_AZ/3_operators.html#arithmetic-operators",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Arithmetic operators",
    "text": "Arithmetic operators\nArithmetic operators are addition +, subtraction -, multiplication *, division /, exponentiation ^, modulo %% and integer division %/%.\nThe addition, subtraction, multiplication, division, and exponentiation are well known. Module and the integer division are less common, but occasionaly useful in programming. Modulo %% is the remainder after integer division, so that 5 %% 2 = 1. The %/% is the integer division 5 %/% 2 = 2. These are used when we want to know how many times something fit in our number, if we need to do something with a certain frequency, or if you want to know if a number is even. But arguably, some of these are displaced by sequence functions, and if we want to fit k elements into categories of size m, ceiling(k/m) gives us exactly that. So personally, I haven’t used modulo or integer division very often.\nThe + and - operators can be both unary and binary, meaning they accept one or two parameters. The meaning and behaviour, such as operator precedence, are different for the unary and binary version.\n\n+ a # unary `+`\n- a # unary `-`\n\na + b # binary `+`\na - b # binary `-`\n\nThis is related to how numbers are parsed by the interpreter (see literals. Details are not important, just remember that the unary and binary operators are different, and that the unary - makes numbers negative. Fun fact, as a consequence of the parsing rules, this is valid R code:\n\n+ - + - 5 + - + - + + - - + - 1\n\n[1] 4\n\n\nAs with most fun facts, you should not ever write a code like this.\n\n\n\n\n\n\nRecycling\n\n\n\nA lot of basic operations in R do something called recycling. For instance, when you add together two vectors with a different number of elements, the shorter vector is being extended by reusing (recycling) its elements.\nFor instance, consider multiplying a vector of length 3 with a vector of length 1: c(1, 2, 3) * 3. This is identical to c(1,2,3) * c(3, 3, 3) because the shorter vector is being recycled. This work well when the length of the longer vector is a multiple of the shorter vector (i.e., longer %% shorter = 0), for instance:\n\nc(1, 2, 3, 4, 5, 6) + c(1, 2)\n\n[1] 2 4 4 6 6 8\n\n\nYou can see that the shorter vector was recycled as c(1,2, 1,2, 1,2), because the length of the longer vector is a multiple of the shorter one. If this is not the case, the shorter vector is still recycled, but a warning is thrown.\n\nc(1,2,3) * c(1,2)\n\nWarning in c(1, 2, 3) * c(1, 2): longer object length is not a multiple of\nshorter object length\n\n\n[1] 1 4 3\n\n\nRecycling allows you to do some fancy tricks, for example if you want to pick every second element of a vector:\n\nc(1,2,3,4,5,6)[c(FALSE, TRUE)]\n\n[1] 2 4 6\n\n\nThis works because the selection vector is being recycled to the full length using the predefined pattern.\n\n\n\nThe strange case of **\nIn some languages such as Python, ** is a power operator. This is also supported in R:\n\n2 ^ 3\n\n[1] 8\n\n2 ** 3\n\n[1] 8\n\n\nStrangely, ** is not documented, ** is not a primitive, and when you type bare ** in R, you will get a curious error:\n\n**\n\nError: <text>:1:1: unexpected '^'\n1: **\n    ^\n\n\nThere is a small note in the ?Arithmetic. Apparently, ** existed in S (the precedesors of R) but was deprecated. For backward compatibility, the R parser kept this functionality and translates ** into ^. Since it is undocumented and not part of the official language specification, do not use **."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#logical-operators-and-functions",
    "href": "posts/baseR_AZ/3_operators.html#logical-operators-and-functions",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Logical operators and functions",
    "text": "Logical operators and functions\nSince we are already talking about the logical operators, I thought it might be more useful to look more closely at the logical type and functions that operate with it.\nLogical operators are negation !, which is a unary operator, and binary logical and & and &&, logical or | and ||. Aside of these operators, there is also a function xor(), helpers isTRUE(), isFALSE(), useful primitives all() and any(), and functions for the creation, testing, and conversion to the logical type: logical(), is.logical(), and as.logical().\n\nLogical operators\nLogical operators are negation !, logical and &, &&, and logical or |, ||.\nThe negation ! operator just makes a FALSE value TRUE and the other way around. The and and or operators are more interesting in the way they work on vectors.\nThe single symbol and and or operators & and | work like + or -, they are applied element-wise and vectors are recycled as required.\n\nc(TRUE, TRUE, FALSE) & c(TRUE, FALSE, FALSE)\n\n[1]  TRUE FALSE FALSE\n\nc(TRUE, TRUE, FALSE) | c(TRUE, FALSE, FALSE)\n\n[1]  TRUE  TRUE FALSE\n\n\nThe double-symbol and and or are not vectorized, they uses only the first element of a vector, while other elements are ignored. Likewise, the output of && and || is a single TRUE or FALSE value. This makes && and || useful when doing control flow operations with if(condition){...}.\n\nc(TRUE, TRUE) && c(TRUE, FALSE) # only the first value is used\n\n[1] TRUE\n\n\n\nShort-circuting\nIn addition, the && and || short-circuits, the second expression is evaluated only if it is required. For instance, in the expression:\na || b\nIf a evaluates to TRUE, the whole expression evaluates to TRUE regardless of b. This means that if a = TRUE, b doesn’t have to be evaluated and in fact isn’t evaluated. So if the b was a function call with some side effects, the side effects (reading file, printing, increasing a counter) are never evaluated. For instance, consider an expression that prints foo and returns TRUE:\n{print(\"foo\"); TRUE}\nIf we use two of these expression with ||, only single foo will be printed:\n\n{print(\"foo\"); TRUE} || {print(\"foo\"); TRUE}\n\n[1] \"foo\"\n\n\n[1] TRUE\n\n\nContrast this with the & or | which do not short-curcuit:\n\n{print(\"foo\"); TRUE} | {print(\"foo\"); TRUE}\n\n[1] \"foo\"\n[1] \"foo\"\n\n\n[1] TRUE\n\n\nIn some languages, this is used as a control structure, since this behaviour can be transformed into:\nif a then a, else b\nBut I haven’t seen this being used in R. Since the R code is typically light on side-effects, I don’t think there is a much value in trying to be cheeky in this way.\n\n\nNA behaviour\nNA or not available is a peculiar value (or values, since there is NA_character_, NA_integer_ atp.) that symbolize a missing value. Most programing languages do not have this (usually, they only have NULL), but R was designed as a domain-specific language for data-analysis and unknown values are a common problem.\nTypically, any numerical calculation involving NA typically results in NA.\n\n3 + NA\n\n[1] NA\n\n5 * NA\n\n[1] NA\n\n\nLogical operations are slightly different and result in NA only if the expression depends on it. You can intepret this dependence in a similar manner as short-circuting, but this works even for the non-short-circuiting operators | and ||.\nFor example, in the x | NA, if x is TRUE, the whole expression is also TRUE. But if x is FALSE, the whole expression depends on the unknown value NA, which means that the expression evaluates to NA.\n\nTRUE | NA\n\n[1] TRUE\n\nFALSE | NA\n\n[1] NA\n\n\nSimilarly, in the x & NA, if x is FALSE, the whole expression is FALSE. But if x is TRUE, the result of the expression depends on the NA and the expression evaluates to NA.\n\nFALSE & NA\n\n[1] FALSE\n\nTRUE & NA\n\n[1] NA\n\n\nIn the same manner, the !NA depends on the NA so it evaluates to NA and so on.\n\n\n\nLogical functions\nNow, lets move to the functions. The isTRUE() and isFALSE() are also useful shorthands for control flow. They detect if the condition is exactly TRUE or FALSE respectively, a good way to avoid pitalls with NA, NULL, which might arise from some operations and should be processed appropriatelly.\nThe logical operations xor() is elementwise exclusive or. It is not an operator, and not a primitive, likely because it is not used very often. You can see that xor() is just a shorthand for (x | y) & !(x & y)\n\nxor\n\nfunction (x, y) \n{\n    (x | y) & !(x & y)\n}\n<bytecode: 0x55a87771d0f8>\n<environment: namespace:base>\n\n\nVery useful if only x or y are allowed, such as if you are using parameters as a mutually exclusive flags. Consider a function that does either foo or bar, but can’t do both at the same time:\nmyfunc = function(x, doFoo=FALSE, doBar=FALSE){\n    if(!xor(doFoo, doBar))\n        stop(\"Must select either doFoo or doBar\")\n\n    if(doFoo)\n        return(foo(x))\n    if(doBar)\n        return(bar(x))\n    }\nWithout xor, the function might not behave as expected, not returning anything if either both conditions are FALSE, or performing only one operation if both conditions are TRUE.\nYou can turn xor() easily into an infix operator %xor%.\n\n`%xor%` = xor\nTRUE %xor% FALSE\n\n[1] TRUE\n\n\nBefore we start talking about the logical type in general, lets quickly mention the all() and any(). These are vectorized and will tell you if all or any value of the vector are TRUE respectively. For efficiency reason, they are primitives, because they are used quite often for the control flow.\n\nvec = c(TRUE, TRUE, FALSE)\nall(vec) # will be FALSE because not all values are TRUE\n\n[1] FALSE\n\nany(vec) # TRUE as at least one value is TRUE\n\n[1] TRUE\n\n\nYou can define a vectorized variant of xor which tells you that there is exactly one TRUE rather easily:\n\none = function(x){\n    sum(x, na.rm=TRUE) == 1\n    }   \none(c(TRUE, TRUE, FALSE)) # will be FALSE\n\n[1] FALSE\n\none(c(FALSE, TRUE, FALSE)) # will be TRUE\n\n[1] TRUE\n\n\n\n\nConversion rules\nThis brings us to an important step, conversion. You can apply logical operators not only on the logical TRUE and FALSE values, but as with many similar operations in R, the values are automatically converted to the correct type.\nConversion is performed internally using the as.logical primitive. Valid conversions are from numeric (that is, both integer and double), complex, and character. For the numeric and complex, 0 is converted into FALSE and non-zero value is converted into TRUE:\n\nas.logical(0)\n\n[1] FALSE\n\nas.logical(5i+3)\n\n[1] TRUE\n\n\nFor the character type, the conversion is a bit more complex. The strings “T”, “TRUE”, “True” and “true” are converted into TRUE, and similarly “F”, “FALSE”, “False” and “false” are converted into FALSE. Everything else, including “TrUe” and similar messy capitalizations, is converted into NA.\n\nas.logical(c(\"T\", \"TRUE\", \"True\", \"true\"))\n\n[1] TRUE TRUE TRUE TRUE\n\nas.logical(c(\"F\", \"FALSE\", \"False\", \"false\"))\n\n[1] FALSE FALSE FALSE FALSE\n\nas.logical(c(\"1\", \"0\", \"truE\", \"foo\"))\n\n[1] NA NA NA NA\n\n\nThe logical(n) is a shorthand for vector(\"logical\", n) and simply create a logical vector of length n with values initialized to FALSE.\n\nlogical(5)\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\n\nWhen converting from logical to numeric, the TRUE and FALSE converts to 1 and 0 respectively. This allows for the convenient use of sum or mean to count the number or the percentage of matches. When converting from logical to character, the TRUE and FALSE gets converted simply to \"TRUE\" and \"FALSE\" strings.\n\n\nRaw vectors\nThe logical operators !, & and | have another meaning for raw vectors. raw is a basic type, alongside integer, double, list, and so on. It represents raw bytes (from 0 to 255), here printed in a hexadecimal format:\n\nas.raw(c(0, 10, 255))\n\n[1] 00 0a ff\n\n\nFor these raw vectors, the logical operators have a slightly different bitwise meaning. See bitwNot, botwAnd, and bitwOr for !, &, and | respectively. We will talk in-depth about raw type and operations on them later in this series."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#relational-operators",
    "href": "posts/baseR_AZ/3_operators.html#relational-operators",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Relational operators",
    "text": "Relational operators\nRelational operatos are smaller than >, larger than >, smaller or equal <=, _larger or equal >=, equal ==, and not equal !=. For numeric (integer and double) and logical (which is converted to numeric), the comparisons are what you might expect, just a standard numerical comparisons.\n\n5L > 2L # integers, the `long` type\n\n[1] TRUE\n\n5.3 > 2.8\n\n[1] TRUE\n\nTRUE > FALSE\n\n[1] TRUE\n\n\nFor raw, the numeric order is used so the comparisons also behaves as expected, and for complex, only the == and != comparisons are implemented.\n\nas.raw(5) > as.raw(2)\n\n[1] TRUE\n\n5+1i > 2+1i\n\nError in 5 + (0+1i) > 2 + (0+1i): invalid comparison with complex values\n\n\n\nString comparisons\nFor character strings, the comparisons are quite a bit more complicated. If you consider only standard english alphabet, the problem might feel obvious. But every language has slightly different rules about order of character in their alphabet. Quoting from the R help page:\n\nBeware of making any assumptions about the collation order: e.g. in Estonian ‘Z’ comes between ‘S’ and ‘T’, and collation is not necessarily character-by-character - in Danish ‘aa’ sorts as a single letter, after ‘z’. In Welsh ‘ng’ may or may not be a single sorting unit: if it is it follows ‘g’.\n\nOn top of this, the order is system and locale dependent. This makes sorting extremely unpredictable when comparing strings accross languages.\nFor more information, see Microsoft page or long unicode explanation.\nI am happy that smarter people solved it and I don’t need to know the details.\n\n\nFloating point comparisons\nThere is a caveat when comparing doubles. You might remember that computers work in a binary. This means that every number is represented by combination of bits that can be 0 or 1. You might start sensing that something is off in here. How can I represent a rational number by just combination of 0 and 1? This is because computers are able to represent perfectly only whole numbers, integer. Anything else is represented imperfectly and you get rounding errors. R is trying to hide this imperfection by rounding when printing, but the abstraction will leak if you try to compare for equality.\n\n(1 - 0.9)\n\n[1] 0.1\n\n(1 - 0.9) == 0.1\n\n[1] FALSE\n\n\nThe > and < still works as intended, but when you are comparing floating point numbers, use all.equal instead and select an appropriate precision (by default sqrt(.Machine$double.eps) is used):\n\nall.equal( (1 - 0.9), 0.1)\n\n[1] TRUE\n\n\nUnlike with string comparison, this is common issue that will significantly influence the performance of your code, especially if you are writing any kind of numerical algorithm. You need to be aware of these issues. See shorter explanation and longer explanation and try to understand them."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#group-generic-methods-and-ops",
    "href": "posts/baseR_AZ/3_operators.html#group-generic-methods-and-ops",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Group generic methods and Ops",
    "text": "Group generic methods and Ops\nSome methods are grouped into groups called group generics functions. These methods are dispatched when any of the grouped functions are called. While it might look strange at first look, this allows for some neat tricks to efficiently define common mathematical operations for a large group of functions.\nFor instance, consider Ops.POSIXt which defines arithmetic, logical and relational operators for the S3 class POSIXt.\n\nOps.POSIXt\n\nfunction (e1, e2) \n{\n    if (nargs() == 1L) \n        stop(gettextf(\"unary '%s' not defined for \\\"POSIXt\\\" objects\", \n            .Generic), domain = NA)\n    boolean <- switch(.Generic, `<` = , `>` = , `==` = , `!=` = , \n        `<=` = , `>=` = TRUE, FALSE)\n    if (!boolean) \n        stop(gettextf(\"'%s' not defined for \\\"POSIXt\\\" objects\", \n            .Generic), domain = NA)\n    if (inherits(e1, \"POSIXlt\") || is.character(e1)) \n        e1 <- as.POSIXct(e1)\n    if (inherits(e2, \"POSIXlt\") || is.character(e2)) \n        e2 <- as.POSIXct(e2)\n    check_tzones(e1, e2)\n    NextMethod(.Generic)\n}\n<bytecode: 0x55a877002078>\n<environment: namespace:base>\n\n\nFirst, the function checks if only a single argument was passed, because unary operators are not defined.\nThen it uses switch statement, which evaluates to TRUE if one of <, >, ==, !=, <=, and >= matches the .Generic variable, which is an automatic variable initialized to the dispatched generics from the Ops group. So if the function call was !POSIXt, the .Generic is the negation operator !. The switch statement thus works as a check whether a particular operator makes sense for the class, throwing error if the operation was not defined.\nThis doesn’t mean that operators not specified in the switch are undefined. In fact, both +.POSIXt and -.POSIXt exists.\n\n\n\n\n\n\nPOSIXt, POSIXlt and POSIXct\n\n\n\nR contains a number of different classes for dates.\nPOSIXct is a signed number of seconds since the begining of 1970 (UCT time zone), the Unix time.\nPOSIXlt is a named list of vectors with sec, min, hour, mday and so on.\nPOSIXct is a really simple and convenient way to keep time, but not very human readable (unless you are Unix guru). POSIXlt is a nice human-readable format, but not very convenient when you want to store precise times in a data.frame\nPOSIXt is a virtual class, both POSIXct and POSIXlt inherits from it. This means that when you define a method for POSIXt, it will automatically work for POSIXct and POSIXlt.\n\n\nSince POSIXt is a virtual class, and math with a number of seconds POSIXct is simpler than math on a complex data structure POSIXlt (see the box), what follows is a conversion into POSIXct, and the call to NextMethod(), which simply calls the appropriate method for the .Generic on the modified parameters. There is nothing simple on NextMethod() and we will talk about it later, when we are talking in-depth about the S3 system.\n\nDouble dispatch\nMethods in the Ops group are special because most of them are binary and they need to do something called double dispatch. For instance, if you are adding objects of class foo and bar, you need to dispatch the correct method for this particular addition, taking in account classes of both objects, not just foo or bar independently. To keep addition comutative, method needs should be identical even if the order of addition is changed (bar + foo).\nS3 has rather primitive double-dispatch system, the rules are as follows:\n\nIf neither objects has a method, use internal method.\nIf only one object has a method, use that method.\nIf both objects have a method, and the methods:\n\nare identical, use that method.\nare not identical, throw a warning and use internal methods.\n\n\nTo demonstrate this, we define a helper function and methods for the + generic for classes foo and bar. These simply return NULL and print a message, which will tell us which method was dispatched.\n\n# helper to make object less wordy\nobj = function(class){\n    structure(1, class=class)\n    }\n`+.foo` = function(...){message(\"foo\")}\n`+.bar` = function(...){message(\"bar\")}\n\nThe first rule is just a normal addition:\n\n1 + 1\n\n[1] 2\n\n\nAccording to the second rule, the +.foo method is dispatched:\n\n1 + obj(\"foo\")\n\nfoo\n\n\nNULL\n\nobj(\"foo\") + 1\n\nfoo\n\n\nNULL\n\nobj(\"foo\") + obj(\"baz\") # no method +.baz\n\nfoo\n\n\nNULL\n\n\nAccording to the third rule, since methods are not identical, we will get a warning.\n\nobj(\"foo\") + obj(\"bar\")\n\nWarning: Incompatible methods (\"+.foo\", \"+.bar\") for \"+\"\n\n\n[1] 2\nattr(,\"class\")\n[1] \"foo\"\n\nobj(\"bar\") + obj(\"foo\")\n\nWarning: Incompatible methods (\"+.bar\", \"+.foo\") for \"+\"\n\n\n[1] 2\nattr(,\"class\")\n[1] \"bar\"\n\n\nFinally, if we redefine the +.foo and the +.bar to be identical, addition works again:\n\n`+.foo` = function(...){message(\"foobar\")}\n`+.bar` = function(...){message(\"foobar\")}\nobj(\"foo\") + obj(\"bar\")\n\nfoobar\n\n\nNULL\n\n\nNotice that if one of the object doesn’t have defined an S3 method, we can make the S3 method that is dispatched quite complex and built-in support for different types. But this mechanism will be fragile and once someone defines method for one of the supported types, our method would be ignored and the dispatch would default to an internal method (with warning). For an explicit double dispatch system that can be further extended, we would need to go for S4 classes."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#example-sparse_vector",
    "href": "posts/baseR_AZ/3_operators.html#example-sparse_vector",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Example: sparse_vector",
    "text": "Example: sparse_vector\nAs an example, we will create an S3 class sparse_vector. There is an S4 class in the Matrix package, which is a more reasonable choice since S4 methods can be extended, but we do this only for demonstration purposes.\nFirst, we will define our class, sparse vector is defined by the vector of values x, vector of indices i and the length of the vector. Normally, we would make a barebone new_sparse_vector constructor, and the sparse_vector one would be an interface that would also check validity of input parameters, but we will keep it simple.\nWe also create a method for the as.vector generics, so that we can easily unroll our sparse vector into a normal one.\n\nsparse_vector = function(x, i, length){\n    structure(list(\n        x = x,\n        i = i,\n        length = length\n        ), class = \"sparse_vector\")\n    }\n\nas.vector.sparse_vector = function(x, ...){\n    y = vector(mode=mode(x$x), length=x$length)\n    y[x$i] = x$x\n    y\n    }\n\nprint.sparse_vector = function(x, ...){\n    y = rep(\".\", x$length)\n    y[x$i] = as.character(x$x)\n    print(y, quote=FALSE)\n    }\n\na = sparse_vector(c(3,5,8), c(2,4,6), 10)\na\n\n [1] . 3 . 5 . 8 . . . .\n\nas.vector(a)\n\n [1] 0 3 0 5 0 8 0 0 0 0\n\n\nWe want to support all operations in the group generics Ops.\n\nOps.sparse_vector = function(e1, e2){\n    if(inherits(e1, \"sparse_vector\"))\n        e1 = as.vector(e1)\n    # If Ops is unary, e2 is missing\n    if(!missing(e2) && inherits(e2, \"sparse_vector\"))\n        e2 = as.vector(e2)\n    NextMethod(.Generic)\n    }\n\na + 2\n\n [1]  2  5  2  7  2 10  2  2  2  2\n\n2 + a\n\n [1]  2  5  2  7  2 10  2  2  2  2\n\na * 2\n\n [1]  0  6  0 10  0 16  0  0  0  0\n\na == 0\n\n [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n- a\n\n [1]  0 -3  0 -5  0 -8  0  0  0  0\n\n\nAnd essentially for free, we suddenly support all operations. But this isn’t very efficient if we are summing two sparse vectors, for instance. So for some operations, we define their own functions.\n\n`+.sparse_vector` = function(e1, e2){\n    message(\"+.sparse_vector dispatched\")\n    if(nargs() == 1L)\n        return(e1)\n\n    if(inherits(e1, \"sparse_vector\") && inherits(e2, \"sparse_vector\")){\n        i = union(e1$i, e2$i) |> sort()\n        j = intersect(e1$i, e2$i) |> sort()\n        l = max(e1$length, e2$length) # ignoring recycling for now\n        y = sparse_vector(rep(0, length(i)), i, l)\n        y$x[i %in% e1$i] = e1$x\n        y$x[i %in% e2$i] = e2$x\n        y$x[i %in% j] = e1$x[e1$i %in% j] + e2$x[e2$i %in% j]\n        return(y)\n        }\n    if(inherits(e1, \"sparse_vector\")){\n        e2[e1$i] = e2[e1$i] + e1$x\n        return(e2)\n        }\n    if(inherits(e2, \"sparse_vector\")){\n        e1[e2$i] = e1[e2$i] + e2$x\n        return(e1)\n        }\n    stop(\"This should be unreachable state\")\n    }\n\nb = sparse_vector(c(1, 2, 3), c(1, 4, 6), 10)\n+ a\n\n+.sparse_vector dispatched\n\n\n [1] . 3 . 5 . 8 . . . .\n\n+ b\n\n+.sparse_vector dispatched\n\n\n [1] 1 . . 2 . 3 . . . .\n\na + b\n\n+.sparse_vector dispatched\n\n\n [1] 1  3  .  7  .  11 .  .  .  . \n\na + rep(1, 10)\n\n+.sparse_vector dispatched\n\n\n [1] 1 4 1 6 1 9 1 1 1 1\n\nb + rep(1, 10)\n\n+.sparse_vector dispatched\n\n\n [1] 2 1 1 3 1 4 1 1 1 1\n\n\nThe code isn’t perfect, we ignore a lot of recycling, which means operations with matrices will not work correctly, and so on. But as an example of the Ops and operator overloading, this should be sufficient. One obvious improvement would be redefining the operator [ to make subsetting of the vector much easier, and thus the code cleaner. We will look at this in the next article."
  },
  {
    "objectID": "posts/baseR_AZ/3_operators.html#summary",
    "href": "posts/baseR_AZ/3_operators.html#summary",
    "title": "Base R from A to Z: Operators (3)",
    "section": "Summary",
    "text": "Summary\nIn this part, we have learned about operators, and more closely explored arithmetic, logical and relational operators. On top of this, we have learned more about group generic functions, double dispatch system, and managed to implement a simple sparse_vector class with working arithmetic, logical and relational operators."
  },
  {
    "objectID": "posts/baseR_AZ/2_functions.html",
    "href": "posts/baseR_AZ/2_functions.html",
    "title": "Base R from A to Z: Types of functions (2)",
    "section": "",
    "text": "In the second part of the series about the base R, I wanted originally to talk about operators. But to talk about properators properly, I wanted to explore how operators are defined first and the difference between classical functions and something called primitives. In the end, the small segway got a bit too big, so I decided to release it as an independent article."
  },
  {
    "objectID": "posts/baseR_AZ/2_functions.html#types-of-functions",
    "href": "posts/baseR_AZ/2_functions.html#types-of-functions",
    "title": "Base R from A to Z: Types of functions (2)",
    "section": "Types of functions",
    "text": "Types of functions\n\nTo understand computations in R, two slogans are helpful:\n\nEverything that exists is an object.\nEverything that happens is a function call.\n– John Chambers (author of S, coauthor of R)\n\n\nAs per the quote, everything that happens in R is a function call. Operators are construct similar to functions, but with special syntax or semantics. But you might have realized that not every function is the same and that R has different types of functions.\nFor instance, when you write the name of a standard function, you will print their code. This doesn’t work with operators and other language elements. To operate with them, you need to escape them, either with quotation marks \" or backticks `. Backticks typically work in most occassions. For instance, we can use backticks to print help of +, print the body of - or call * as if it was a function:\n\n?`+` # prints a help-page of +\n`-` # prints the body of -\n\nfunction (e1, e2)  .Primitive(\"-\")\n\n`*`(3,5) # call as if * was a normal function\n\n[1] 15\n\n\nOperators are special kind of functions, but so are other language elements like for, return, or in fact even ( and {. But unlike with operators, calling language elements like a function doesn’t work. We will talk about these language elements in detail some other time.\nThese special functions are called primitives. Primitives are special in many ways. Outside of primitives, all other functions are standard functions that either call R code, or call a compiled C or Fortran code through the interfaces .Internal, .External, .C, .Call or .Fortran.\nTo explore these function types in base, we will define a helper functions. And because there would be a lot of repeated code, we will construct these functions with a function factory.\n\nis_function_type_factory = function(pattern, fixed=TRUE){\n    force(fixed) # force evaluation\n\n    function(x){\n        if(!is.function(x))\n            return(FALSE)\n        \n        body = body(x)\n        if(is.null(body))\n            return(FALSE) # primitives don't have body\n\n        deparse(body) |> grep(pattern=pattern, fixed=fixed) |> any()\n        }\n    }\n\nis.internal = is_function_type_factory(\".Internal\")\nis.external = is_function_type_factory(\".External\")\nis.ccall    = is_function_type_factory(\".C\") # will match .C and .Call\nis.fortran  = is_function_type_factory(\".Fortran\")\n\n# Get all functions from base, we did this before\nfunctions = Filter(is.function, sapply(ls(baseenv()), get, baseenv()))\n\nSo out of 1242, there are 185 primitives, 415 internals, 0 external calls, 3 calls using the .C or .Call interface, 6 calls to Fortran, with the rest being pure R functions.\n\nPrimitives\nPrimitives are special functions that form the core of R language. Normal functions (called closures in R) have a list of arguments called formals, a body, and an enclosing environment (thus called closures).\n\n# formals, body and environment of `is.internal`\nnot_null = Negate(is.null)\nhas_fbe = function(x){c(\n    \"formals\"     = formals(x) |> not_null(),\n    \"body\"        = body(x) |> not_null(),\n    \"environment\" = environment(x) |> not_null()\n    )}\n    \nhas_fbe(is.internal)\n\n    formals        body environment \n       TRUE        TRUE        TRUE \n\n\nCompared to normal functions, primitives do not have any formals, body, or enclosing environment.\n\nhas_fbe(`-`)\n\n    formals        body environment \n      FALSE       FALSE       FALSE \n\n\nThis is why we put an additional check for body(x) |> is.null() in our function factory. So what about the printed body of - that we saw before? It was a fake! R is lying to us here.\n\n`-` # output of this is fake\n\nfunction (e1, e2)  .Primitive(\"-\")\n\n\n\nminus = function(e1, e2) .Primitive(\"-\")\nminus\n\nfunction(e1, e2) .Primitive(\"-\")\n\n\nSee the extra space in the original -? Now watch this. Calling minus(1,2) just prints the original -.\n\nminus(1,2) # just prints the original `-`\n\nfunction (e1, e2)  .Primitive(\"-\")\n\n\nTo get the correct result, we need to call minus()(1,2).\n\nminus()(1,2)\n\n[1] -1\n\n\nThis is because our function returns the .Primitive(\"-\") which then performs the actual call to the - primitive.\nAll the special language elements like for, ( are primitives, so are the functions like .Internal or .Call that communicate with the internal or external libraries. Finally, there is also a performance consideration, many non-special functions are primitives because these call need to be performant.\n\n\nGenerics\nOne reason why I am talking about these types of functions is because of generics. Generics1 are types of functions that when called, they dispatch a function specific to the type of input object. Typically, the type of object is called a class, and the specific function is called a method. This is the core of the S3 object-oriented system. For instance, in most cases you don’t need to worry what kind of object you are working with and call print anyway, which will then dispatch an appropriate method based for the class of the object, such as print.data.frame or print.Date. This makes interactive use quite convenient, but also allows you to write a more generic code. For instance, instead of having to expect every single possible class in your function, you can rest assured that as.character will provide you a reasonable output.\nTypical S3 generic functions would look like this:\n\n\nfunction (x, ...) \nUseMethod(\"print\")\n<bytecode: 0x558f238a6c58>\n<environment: namespace:base>\n\n\nJust a single call to UseMethod(\"print\") alternatively UseMethod(\"print\", x) to make the object for which the method will be dispatched (x in this case) explicit. Notice that no other argument parsing is happening there, this is done behind the curtain.\n\n\nGeneric primitives\nPrimitives can be generics as well, even without the use of UseMethod. There are a few ways how this is achieved.\nFirst of all, there are S3 prototype functions in the .GenericsArgsEnv environment. They look like your standard S3 generic function, just a call to UseMethod.\n\nget_objects = function(x){\n    if(is.character(x))\n        x = getNamespace(x)\n\n    sapply(x |> ls(), get, x)\n    }\n\nprimitive_generics = get_objects(.GenericArgsEnv)\nprimitive_generics[1]\n\n$`-`\nfunction (e1, e2) \nUseMethod(\"-\")\n<bytecode: 0x558f21115ed8>\n<environment: namespace:base>\n\nprimitive_generics |> names() |> head(10)\n\n [1] \"-\"   \"!\"   \"!=\"  \"*\"   \"/\"   \"&\"   \"%/%\" \"%%\"  \"^\"   \"+\"  \n\n\nHowever, I am not sure if they are actually used during calls or are there for other reason, such as documentation. There is a similar environment .ArgsEnv that contains primitives that are not generics.\n\nprimitive_not_generic = get_objects(.ArgsEnv)\n\nprimitive_not_generic[[\"seq_len\"]]\n\nfunction (length.out) \nNULL\n<bytecode: 0x558f21104b30>\n<environment: namespace:base>\n\n\nThese functions, when executed, just return NULL.\n\nprimitive_not_generic[[\"seq_len\"]](5)\n\nNULL\n\n\nCompare this to a standard call to seq_len\n\nseq_len(5)\n\n[1] 1 2 3 4 5\n\n\nThis suggests that these functions, likely both .GenericsArgsEnv and .ArgsEnv are not involved in the function dispatch, or if they are, they are involved much later after the .Primitive() call is evaluated.\nThis brings us to the second way how primitives can be generic. But this dispatch is being performed directly in the internal C code using either the DispatchOrEval call or DispatchGeneric. I will stop here and won’t got deeper, because the situation is quickly getting complicated. For instance, despite the manual saying that something called group generics are using the DispatchGeneric, this is not actually the case and this function doesn’t exist in the C code. Instead, many generics are grouped, thus called group, have a complex system of dispatching based utilizing DispatchGroup (instead of DispatchGeneric), switch and integer values likely related to the functions in the src/main/names.c source code.\nYou can see which functions are group generics in two ways, reading the help file for ?groupGeneric (it has no associated object) or by removing non-group generic functions from all primitive generics:\n\nsetdiff(primitive_generics |> names(), .S3PrimitiveGenerics)\n\n [1] \"-\"        \"!\"        \"!=\"       \"*\"        \"/\"        \"&\"       \n [7] \"%/%\"      \"%%\"       \"^\"        \"+\"        \"<\"        \"<=\"      \n[13] \"==\"       \">\"        \">=\"       \"|\"        \"abs\"      \"acos\"    \n[19] \"acosh\"    \"all\"      \"any\"      \"Arg\"      \"asin\"     \"asinh\"   \n[25] \"atan\"     \"atanh\"    \"ceiling\"  \"Conj\"     \"cos\"      \"cosh\"    \n[31] \"cospi\"    \"cummax\"   \"cummin\"   \"cumprod\"  \"cumsum\"   \"digamma\" \n[37] \"exp\"      \"expm1\"    \"floor\"    \"gamma\"    \"Im\"       \"lgamma\"  \n[43] \"log\"      \"log10\"    \"log1p\"    \"log2\"     \"max\"      \"min\"     \n[49] \"Mod\"      \"prod\"     \"range\"    \"Re\"       \"round\"    \"sign\"    \n[55] \"signif\"   \"sin\"      \"sinh\"     \"sinpi\"    \"sqrt\"     \"sum\"     \n[61] \"tan\"      \"tanh\"     \"tanpi\"    \"trigamma\" \"trunc\"   \n\n\nNote that these lists of functions are not generated from the C source code, so there is no way other than reading the C source code to know if a primitive function is generic or not.\n\n\nOperator overloading\nEquations would be quite messy if you had to write a different + for scalars, vector and matrices. In case of operators, this is called operator overloading and can be a dangerous tool if not done carefully.\nThe whole point of operator overloading is that you can have quite complex objects and operate with them in a nice and polite manner as long as the semantics of operators make sense. For instance, the Matrix package defines sparse matrices. Sparse matrices are matrices where the majority of elements are equal to zero. Because of this, it is quite a bit more efficient if they are respresented not as a standard matrix with n*m elements, but with a special representation where you represent only elements that are non-zero. This saves memory and makes some operations faster. At the same time, you want them to behave like standard matrices with operations like addition, multiplication, or subsetting. So in standard S3 way (or S4 in this case), you overload the + operator to dispatch a particular function for addition of two standard matrices, one standard and one sparse, or two sparse matrices. From user perspective, nothing has changed and the operation looks the same M + N regardless of what types the matrices are summed. In languages like Java, which forgeos operator overloading in favour of heavy object-oriented system, you would have to do something of this sort:\n# without operator overloading\nM.add(N)\nYou can see that complex equation might look quite messy due to this. At least Java has function overloading. Without that, you would have to detect the particular type of objects and dispatch an appropriate function by yourself. This is exactly what the R source code written in C has to do.\nNote that this operator overloading does not always work and you can’t easily overload operators for basic types. For instance, some languages like to overload the + operator for the addition of strings, performing string concatenation. This makes sense in some cases, doesn’t in other cases and is another contentious problems, there is a whole discussion about this on the R mailing list.\n\n`+.character` = function(x,y){paste0(x,y)}\n\"foo\" + \"bar\"\n\nError in \"foo\" + \"bar\": non-numeric argument to binary operator\n\n\nThis is character is a basic type, which do not have a class and thus do not immediatelly work with all primitive generics this way. What matters here is the attribute class that is added to S3 objects. But if you try to explore this attribute with the class(), R will lie to you. You need to use the oldClass() function to see the S3 attribute.\n\nclass(\"foo\") # will lie to you\n\n[1] \"character\"\n\noldClass(\"foo\")\n\nNULL\n\n\nThis overloading will work well for user-defined S3 classes.\n\n`+.foobar` = function(x,y){paste0(x,y)}\nstructure(\"foo\", class = \"foobar\") + structure(\"bar\", class = \"foobar\")\n\n[1] \"foobar\"\n\n\nOr you can define the class explicitelly as a character.\n\n`+.character` = function(x,y){paste0(x,y)}\nstructure(\"foo\", class = \"character\") + structure(\"bar\", class = \"character\")\n\n[1] \"foobar\"\n\n\nBut it is better to not due this.\nAnother way is to overwrite the + function with user-defined function, but don’t do this either. If you think that the + semantics makes sense for strings, just define the %+% operator:\n\n`%+%` = function(x,y){paste0(x,y)}\n\"foo\" %+% \"bar\"\n\n[1] \"foobar\"\n\n\nOne famous case of using the operator + in a special way is to combine graphical elements in the ggplot package.\nOperator overloading is especially useful for the equality operator =, but also for various subsetting operators [ or [[, as well as for the replacement operators [<-. We will talk about this next time.\n\n\nspecial vs builtin\nAnd just for completeness, Primitives and internal functions are also divided into special and builtin.\n\nprimitives = Filter(is.primitive, functions)\nsplit(primitives |> names(), sapply(primitives, typeof)) |>\n    sapply(head, n=10, simplify=FALSE) # sample of bultin and specials\n\n$builtin\n [1] \"-\"   \":\"   \"!\"   \"!=\"  \"(\"   \"*\"   \"/\"   \"&\"   \"%*%\" \"%/%\"\n\n$special\n [1] \"::\"   \":::\"  \"[\"    \"[[\"   \"[[<-\" \"[<-\"  \"{\"    \"@\"    \"@<-\"  \"&&\"  \n\n\nThe difference between them is that builtin functions evaluate all their arguments before being passed to the internal implementation, while special don’t evaluate their arguments. When profiling, builtin functions are also counted as a function calls, while special aren’t. Only a small number of functions are trully special :). And while we can look which primitives are builtin or special, we can’t do so with internal functions. For instance, according to the documentation, cbind is special internal, while grep is builtin internal. But when you to get their type, all you get is a closure.\n\nc(\"cbind\" = typeof(cbind), \"grep\" = typeof(grep))\n\n    cbind      grep \n\"closure\" \"closure\" \n\n\nUnless you want to join the development team of R, you do not need to know about this distinction."
  },
  {
    "objectID": "posts/baseR_AZ/2_functions.html#summary",
    "href": "posts/baseR_AZ/2_functions.html#summary",
    "title": "Base R from A to Z: Types of functions (2)",
    "section": "Summary",
    "text": "Summary\nEverything that happen in R is a function call, but for performance and parsing purpose, R has different types of functions. The classic functions in R are closures, but there are special kind of functions called primitives. Most operators are primitives and some primitives can also be generics, which connects them to the S3 dispatch system. This allows operators to be overloaded for user-defined classes, but not for basic types, despite not being typical S3 generics with UseMethod() call."
  },
  {
    "objectID": "posts/hello_world/index.html",
    "href": "posts/hello_world/index.html",
    "title": "Hello World!",
    "section": "",
    "text": "So I decided to do blogging. Again.\n\nWhat can you expect?\nSince I am computational biologists, you can expect some statistics and data science with biological motivations, usually evolutionary biology or bioinformatics.\nRegarding programming things, I will write mostly about R. I am kind of purist so I am one of the few people who prefers base R, including base graphics, so I will try to write a few articles regarding some forgotten treasures there. For example, since base does not divide its functions into namespaces (like Python’s standard library), it is hard to find a complex documentation about all the string-manipulation functions, so many people might not know that functions like trimws() even exists.\nOutside of R, I use also Python, and I finally starter using C/C++, at least in connection with R.\n\n\nWhy wrote blogs? Aren’t there already plenty of them?\nMy memory is terrible and I have a bad tendency of leaving projects unfinished. Blogposts will serve as a good written memory and something that will force me to finish projects to a state where I woldn’t be ashamed of them being public. This goes double for various learning projects. So you see, this blog is not for you, it is for me. But since most of the popular blogs originated in this way, I hope that eventually,\n\n\nMy previous attempts at blogging\nMy previous attempts at blogging didn’t get far. One was named “Mammoths on Mars”, a cool name, something about why developing science to such a degree that we could have mammoths on Mars would be so frigging awesome. But all I got from it was a half-assed post about why testing for phylogenetic signal from data that could arise from an evolutionary process is so complicated. Something that would plague me in the future. Not the half-assed blogpost, but the phylogenetic signal.\nThat was 8 years ago, I was just learning about static site generators which were becoming increasingly popular. Finally, small sites with pure HTML generated from markup format! And since I was using quite a bit Python at that time, I didn’t pick the omnipresent Jekyll, but a Python-based Pelican. But the documentation wasn’t there yet, everyone was talking about templates, but no one really explained what are those in the first places. That was not very beginner friendly.\nMy second attempt came years later, because I really wanted to understand all these templates. Which was a cool learning experience, because you can create a static site generator really easily! You can see the attempt here, only 7 direct dependencies (6, if I remove magrittr) and ~300 lines of code. The site is technically still lives, but I don’t update it often because getting good photos of food is so damn hard. Something about proper light and clean table.\nThe learning experience was cool, I learned a lot about CSS at least. I still dislike the whole experience, which was the reason why for the third time, I picked something pre-backed. And Quarto was recently released. So here we are, after a week fiddling with some internals, parameters, trying to modify the .scss bootstrap theme and finding that it doesn’t do anything. But perfect is the enemy of good, and I really want to write some blogposts and not fiddle with the parameters that much.\nSo here we are, now you know everything. Hope you will find content interesting or at least in some way entertaining."
  }
]